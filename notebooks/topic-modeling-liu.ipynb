{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First example\n",
    "1. Defining the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"cryptography can be used for preventing data leakage in computer security\",\n",
    "\"supervised learning and unsupervised learning are the two main groups of methods in machine learning\",\n",
    "\"while in supervised learning we have access to the target variable in unsupervised learning we do not have such a variable\",\n",
    "\"there are some methods in security for reducing the risk of information leakage like authentication and cryptography\",\n",
    "\"topic modeling in an unsupervised machine learning model and therefore we do not have target variables\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Preprocessing the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the next step, we want to preprocess the corpus. One crucial aspect of preprocessing is removing the stop words. As mentioned in [this Wikipedia entry](https://en.wikipedia.org/wiki/Stop_word), stop words are filtered out before or after processing natural language data (text). Though \"stop words\" usually refers to the most common words in a language, there is no single universal list of stop words used by all-natural language processing tools. In our example, it seems that the following is a good initial candidate for the stop words list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\"can\",\"be\",\"for\",\"two\",\"the\",\"for\",\"we\",\"in\",\"not\",\"do\",\\\n",
    "              \"are\",\"to\",\"an\",\"there\",\"some\",\"have\",\"a\",\"and\",\"of\",\"like\",\"while\",\"therefore\",\"such\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to remove the stop words and make the docs lower case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc(doc):\n",
    "    return \" \".join([word for word in doc.lower().split() if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cryptography used preventing data leakage computer security'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_doc(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_clean = [clean_doc(doc) for doc in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cryptography used preventing data leakage computer security',\n",
       " 'supervised learning unsupervised learning main groups methods machine learning',\n",
       " 'supervised learning access target variable unsupervised learning variable',\n",
       " 'methods security reducing risk information leakage authentication cryptography',\n",
       " 'topic modeling unsupervised machine learning model target variables']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next phase, we need to split the docs in the corpus to a list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_clean = [doc.split() for doc in corpus_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cryptography',\n",
       "  'used',\n",
       "  'preventing',\n",
       "  'data',\n",
       "  'leakage',\n",
       "  'computer',\n",
       "  'security'],\n",
       " ['supervised',\n",
       "  'learning',\n",
       "  'unsupervised',\n",
       "  'learning',\n",
       "  'main',\n",
       "  'groups',\n",
       "  'methods',\n",
       "  'machine',\n",
       "  'learning'],\n",
       " ['supervised',\n",
       "  'learning',\n",
       "  'access',\n",
       "  'target',\n",
       "  'variable',\n",
       "  'unsupervised',\n",
       "  'learning',\n",
       "  'variable'],\n",
       " ['methods',\n",
       "  'security',\n",
       "  'reducing',\n",
       "  'risk',\n",
       "  'information',\n",
       "  'leakage',\n",
       "  'authentication',\n",
       "  'cryptography'],\n",
       " ['topic',\n",
       "  'modeling',\n",
       "  'unsupervised',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'model',\n",
       "  'target',\n",
       "  'variables']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Creating the dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to create a dictionary which more having than the words, has an id  assigned to each word. For this, gensim can help us as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(corpus_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 computer\n",
      "1 cryptography\n",
      "2 data\n",
      "3 leakage\n",
      "4 preventing\n",
      "5 security\n",
      "6 used\n",
      "7 groups\n",
      "8 learning\n",
      "9 machine\n",
      "10 main\n",
      "11 methods\n",
      "12 supervised\n",
      "13 unsupervised\n",
      "14 access\n",
      "15 target\n",
      "16 variable\n",
      "17 authentication\n",
      "18 information\n",
      "19 reducing\n",
      "20 risk\n",
      "21 model\n",
      "22 modeling\n",
      "23 topic\n",
      "24 variables\n"
     ]
    }
   ],
   "source": [
    "for id, word in dictionary.iteritems():\n",
    "    print(id, word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Creating M1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to create M1. In other words, we want a model to tell us for each document and each word what is the frequency of the word in the document. We call these models [bag of words (bow)](https://en.wikipedia.org/wiki/Bag-of-words_model). If we call the *doc2bow* method of the dictionary on a document, it will give us the document's bow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, 2), (12, 1), (13, 1), (14, 1), (15, 1), (16, 2)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.doc2bow(corpus_clean[2]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output, we can conclude that word with the id of 8 (learning) has been repeated two times in document 3 (corpus_clean\\[2\\]). So now we can make M1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = [dictionary.doc2bow(doc) for doc in corpus_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)],\n",
       " [(7, 1), (8, 3), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1)],\n",
       " [(8, 2), (12, 1), (13, 1), (14, 1), (15, 1), (16, 2)],\n",
       " [(1, 1), (3, 1), (5, 1), (11, 1), (17, 1), (18, 1), (19, 1), (20, 1)],\n",
       " [(8, 1), (9, 1), (13, 1), (15, 1), (21, 1), (22, 1), (23, 1), (24, 1)]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Creating and training th LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "ldamodel = Lda(M1, num_topics=2, id2word = dictionary, passes=3,random_state =0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first three arguments of Lda are clear. Regarding the other arguments, note that Lda may not be able to find optimal topics initially. Therefore, we can give it the possibility to go over the corpus for more than one pass. Usually, more passes increase the model's quality, however after some point, it converges, and therefore more passes do not give better topic models. Regarding the last parameter, regard that the Lda implementation of gensim has a certain degree of randomness. Therefore, there is no guarantee that you get the same topics each time you run the model. By fixing the random_state to some fixed number, we will be sure that the results will be the same after each run. I fixed this so that you also get the same results of this notebook, and we can discuss the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have the model and M2 and M3 has been generated. Let us see M2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.098*\"learning\" + 0.067*\"cryptography\" + 0.067*\"security\" + 0.067*\"leakage\" + 0.066*\"methods\" + 0.042*\"unsupervised\" + 0.041*\"computer\" + 0.041*\"data\" + 0.041*\"supervised\" + 0.041*\"used\"'),\n",
       " (1,\n",
       "  '0.120*\"learning\" + 0.087*\"unsupervised\" + 0.083*\"target\" + 0.077*\"variable\" + 0.055*\"machine\" + 0.053*\"supervised\" + 0.052*\"topic\" + 0.052*\"variables\" + 0.052*\"modeling\" + 0.052*\"model\"')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows that for topic 0 (the first topic), cryptography has the weight of 0.067, and for topic 1(the second topic), learning has the weight of 0.12. You can also use the show_topic method of the model to focus on each topic. You can pass two parameters to it. The first one is the topic number, and the second one is the number of top words of the topic which you want to get the weights of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('learning', 0.12041809),\n",
       " ('unsupervised', 0.08701295),\n",
       " ('target', 0.0833895),\n",
       " ('variable', 0.076944105),\n",
       " ('machine', 0.055268224)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.show_topic(topicid=1,topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the model, the first step is to check the generated topics and see whether they make sense. In the above example, it seems that the model did a good job in finding the security and machine learning topics. Note that interpretation of the name of the topic is on us. It seems that we can call the first topic computer security and the second one machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another step is to test the model on some unseen documents to see whether it would be successful in finding each topic's weight in the document. For this, let us try it on the first paragraph of [this page](https://en.wikipedia.org/wiki/Computer_security)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"\"\"Computer security, cybersecurity or information technology security (IT security) is the protection of computer \n",
    "systems and networks from information disclosure, theft of or damage to their hardware, software, or electronic data,\n",
    "as well as from the disruption or misdirection of the services they provide\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_clean = clean_doc(doc).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_bow = dictionary.doc2bow(doc_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.91121024), (1, 0.08878979)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel[doc_bow]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is shown that the model has assigned the weight of 0.91 for the first topic, which is the computer security topic which confirms that the model is doing a good job on unseen data also."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another step that can help in evaluating the model is to visualize it. To do this, the optimal solution is to use the pyLDAvis package as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el2042021384699185281242951228\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el2042021384699185281242951228_data = {\"mdsDat\": {\"x\": [0.04885953664779663, -0.04885953664779663], \"y\": [0.0, 0.0], \"topics\": [1, 2], \"cluster\": [1, 1], \"Freq\": [55.84932199851023, 44.15067800148977]}, \"tinfo\": {\"Term\": [\"target\", \"variable\", \"topic\", \"variables\", \"modeling\", \"model\", \"unsupervised\", \"access\", \"cryptography\", \"security\", \"leakage\", \"methods\", \"learning\", \"machine\", \"supervised\", \"computer\", \"data\", \"used\", \"preventing\", \"main\", \"authentication\", \"risk\", \"groups\", \"reducing\", \"information\", \"cryptography\", \"security\", \"leakage\", \"methods\", \"computer\", \"data\", \"used\", \"preventing\", \"main\", \"authentication\", \"risk\", \"groups\", \"reducing\", \"information\", \"learning\", \"supervised\", \"machine\", \"unsupervised\", \"access\", \"variable\", \"model\", \"modeling\", \"variables\", \"topic\", \"target\", \"target\", \"topic\", \"variables\", \"modeling\", \"model\", \"variable\", \"access\", \"unsupervised\", \"machine\", \"supervised\", \"learning\", \"information\", \"reducing\", \"groups\", \"risk\", \"authentication\", \"main\", \"preventing\", \"used\", \"data\", \"computer\", \"methods\", \"leakage\", \"security\", \"cryptography\"], \"Freq\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.4984757683863814, 1.489336497367555, 1.4861477641147425, 1.4796854111930546, 0.9088270927167963, 0.9086090511382816, 0.9057298204161929, 0.9040647983317107, 0.8955112435837187, 0.8930875699611679, 0.8877674386673862, 0.8874727496484852, 0.8824298307585327, 0.8822276845775356, 2.182273299663029, 0.9070309127972992, 0.8709572651836694, 0.9272593457451045, 0.3971298209727761, 0.4901923385091739, 0.3215161847844865, 0.32122532397650605, 0.31959910413858206, 0.31620113003127326, 0.3769712528742697, 1.4726811828482027, 0.9165534763069842, 0.9131372177636813, 0.9115020820956231, 0.9112099761019731, 1.358853792928051, 0.8351911017851441, 1.5366722639283004, 0.9760518487833956, 0.9397849159825971, 2.126616107667738, 0.3474990598073594, 0.34729560535119663, 0.3422260531996897, 0.34193003272256617, 0.33658146671541284, 0.33414481588504874, 0.3255455509591465, 0.3238716980890021, 0.32097725006115746, 0.3207580060918244, 0.36406962756245453, 0.35757260473589764, 0.3543672677726941, 0.3451790869003598], \"Total\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.8436548552867413, 1.843703765140249, 1.84372036885064, 1.8437550387555093, 1.2295850988086208, 1.229586301199439, 1.229601518505195, 1.2296103492908572, 1.2296560594687675, 1.2296690366765808, 1.2296974713899522, 1.229698802848175, 1.2297254361097294, 1.229726744384895, 4.308889407330767, 1.8468158287798961, 1.847009113967065, 2.4639316096734047, 1.2323209227579202, 1.849046131437225, 1.2327261608864597, 1.2327274060721292, 1.2327363219022633, 1.2327546063382575, 1.8496524357224724, 1.8496524357224724, 1.2327546063382575, 1.2327363219022633, 1.2327274060721292, 1.2327261608864597, 1.849046131437225, 1.2323209227579202, 2.4639316096734047, 1.847009113967065, 1.8468158287798961, 4.308889407330767, 1.229726744384895, 1.2297254361097294, 1.229698802848175, 1.2296974713899522, 1.2296690366765808, 1.2296560594687675, 1.2296103492908572, 1.229601518505195, 1.229586301199439, 1.2295850988086208, 1.8437550387555093, 1.84372036885064, 1.843703765140249, 1.8436548552867413], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"], \"logprob\": [25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.701900005340576, -2.7079999446868896, -2.710200071334839, -2.7144999504089355, -3.2019999027252197, -3.202199935913086, -3.205399990081787, -3.207200050354004, -3.2167000770568848, -3.219399929046631, -3.225399971008301, -3.2256999015808105, -3.2314000129699707, -3.2316999435424805, -2.3259999752044678, -3.203900098800659, -3.244499921798706, -3.1819000244140625, -4.029900074005127, -3.8192999362945557, -4.241099834442139, -4.242000102996826, -4.247099876403809, -4.257699966430664, -4.081999778747559, -2.4842000007629395, -2.9584999084472656, -2.9621999263763428, -2.9639999866485596, -2.9642999172210693, -2.56469988822937, -3.0513999462127686, -2.441699981689453, -2.8956000804901123, -2.9333999156951904, -2.11680006980896, -3.928299903869629, -3.9289000034332275, -3.9435999393463135, -3.944499969482422, -3.960200071334839, -3.9674999713897705, -3.9935998916625977, -3.998699903488159, -4.007699966430664, -4.008399963378906, -3.881700038909912, -3.8996999263763428, -3.9086999893188477, -3.934999942779541], \"loglift\": [25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.3752, 0.3691, 0.3669, 0.3625, 0.2802, 0.28, 0.2768, 0.275, 0.2654, 0.2627, 0.2567, 0.2564, 0.2506, 0.2504, -0.0978, -0.1285, -0.1692, -0.3948, -0.5499, -0.7451, -0.7614, -0.7623, -0.7674, -0.7781, -1.0081, 0.5896, 0.5212, 0.5175, 0.5157, 0.5154, 0.5095, 0.4286, 0.3454, 0.1798, 0.142, 0.1114, -0.4462, -0.4468, -0.4615, -0.4624, -0.4781, -0.4854, -0.5114, -0.5165, -0.5255, -0.5262, -0.8047, -0.8226, -0.8316, -0.8579]}, \"token.table\": {\"Topic\": [2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2], \"Freq\": [0.8114769306699844, 0.813226949832529, 0.8132824649297782, 0.5424008713629164, 0.8132816696351596, 0.8132072648065066, 0.8131887873189231, 0.5423815980421107, 0.4641567259993666, 0.4641567259993666, 0.5414158449127346, 0.5414158449127346, 0.813235532244697, 0.5423713991176269, 0.8112101711874882, 0.8112093517790162, 0.8132657638874962, 0.8131896524508169, 0.8132081453088453, 0.542386482529058, 0.5414725087453104, 0.5414725087453104, 0.5406421123703714, 0.811191452750174, 0.4058554206918716, 0.8117108413837432, 0.8132716046217009, 0.5408193895209747, 0.8112034846648125], \"Term\": [\"access\", \"authentication\", \"computer\", \"cryptography\", \"data\", \"groups\", \"information\", \"leakage\", \"learning\", \"learning\", \"machine\", \"machine\", \"main\", \"methods\", \"model\", \"modeling\", \"preventing\", \"reducing\", \"risk\", \"security\", \"supervised\", \"supervised\", \"target\", \"topic\", \"unsupervised\", \"unsupervised\", \"used\", \"variable\", \"variables\"]}, \"R\": 25, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el2042021384699185281242951228\", ldavis_el2042021384699185281242951228_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el2042021384699185281242951228\", ldavis_el2042021384699185281242951228_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el2042021384699185281242951228\", ldavis_el2042021384699185281242951228_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=             x    y  topics  cluster       Freq\n",
       "topic                                          \n",
       "0      0.04886  0.0       1        1  55.849322\n",
       "1     -0.04886  0.0       2        1  44.150678, topic_info=            Term      Freq     Total Category  logprob  loglift\n",
       "15        target  1.000000  1.000000  Default  25.0000  25.0000\n",
       "16      variable  1.000000  1.000000  Default  24.0000  24.0000\n",
       "23         topic  1.000000  1.000000  Default  23.0000  23.0000\n",
       "24     variables  1.000000  1.000000  Default  22.0000  22.0000\n",
       "22      modeling  1.000000  1.000000  Default  21.0000  21.0000\n",
       "..           ...       ...       ...      ...      ...      ...\n",
       "0       computer  0.320758  1.229585   Topic2  -4.0084  -0.5262\n",
       "11       methods  0.364070  1.843755   Topic2  -3.8817  -0.8047\n",
       "3        leakage  0.357573  1.843720   Topic2  -3.8997  -0.8226\n",
       "5       security  0.354367  1.843704   Topic2  -3.9087  -0.8316\n",
       "1   cryptography  0.345179  1.843655   Topic2  -3.9350  -0.8579\n",
       "\n",
       "[75 rows x 6 columns], token_table=      Topic      Freq            Term\n",
       "term                                 \n",
       "14        2  0.811477          access\n",
       "17        1  0.813227  authentication\n",
       "0         1  0.813282        computer\n",
       "1         1  0.542401    cryptography\n",
       "2         1  0.813282            data\n",
       "7         1  0.813207          groups\n",
       "18        1  0.813189     information\n",
       "3         1  0.542382         leakage\n",
       "8         1  0.464157        learning\n",
       "8         2  0.464157        learning\n",
       "9         1  0.541416         machine\n",
       "9         2  0.541416         machine\n",
       "10        1  0.813236            main\n",
       "11        1  0.542371         methods\n",
       "21        2  0.811210           model\n",
       "22        2  0.811209        modeling\n",
       "4         1  0.813266      preventing\n",
       "19        1  0.813190        reducing\n",
       "20        1  0.813208            risk\n",
       "5         1  0.542386        security\n",
       "12        1  0.541473      supervised\n",
       "12        2  0.541473      supervised\n",
       "15        2  0.540642          target\n",
       "23        2  0.811191           topic\n",
       "13        1  0.405855    unsupervised\n",
       "13        2  0.811711    unsupervised\n",
       "6         1  0.813272            used\n",
       "16        2  0.540819        variable\n",
       "24        2  0.811203       variables, R=25, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(ldamodel, M1, dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure enables you to see the topics in a two-dimensional space. Circles in this figure represent the topics. If you hover on the words, you can see their weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other step for evaluating a topic model is computing a quantitative metric for comparing the different topic models that we can make on a specific corpus.  We will discuss one of these metrics, which is the coherence score, in the following example.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second example\n",
    "For this example, I will use paragraphs of [this page](https://www.sigsac.org/ccs/CCS2020/proceedings.html) as  the documents of a corpus. This is the proceedings of the CCS 2020 conference. We can directly scrap the page or save its text in a file and use that file. We will follow the second approach for simplicity here. I have saved the text in the _ccs2020.corpus_ file. Let us read the corpus first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [doc for doc in open('ccs2020.corpus', encoding='utf-8') if len(doc) > 80]\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have limited the corpus to the paragraphs  which have the length of at least 80 so that the authors' names are not included in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tor exit blocking, in which websites disallow clients arriving from Tor, is a growing and potentially existential threat to the anonymity network. This paper introduces HebTor, a new and robust architecture for exit bridges---short-lived proxies that serve as alternative egress points for Tor. A key insight of HebTor is that exit bridges can operate as Tor onion services, allowing any device that can create outbound TCP connections to serve as an exit bridge, regardless of the presence of NATs and/or firewalls. HebTor employs a micropayment system that compensates exit bridge operators for their services, and a privacy-preserving reputation scheme that prevents freeloading. We show that HebTor effectively thwarts server-side blocking of Tor, and we describe the security, privacy, and legal implications of our design.\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we follow the same steps as the previous example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.015*\"that\" + 0.008*\"on\" + 0.008*\"this\" + 0.007*\"is\" + 0.007*\"our\" + 0.005*\"by\" + 0.005*\"as\" + 0.005*\"it\" + 0.004*\"from\" + 0.004*\"attack\"')\n",
      "(1, '0.012*\"that\" + 0.011*\"is\" + 0.009*\"on\" + 0.006*\"this\" + 0.006*\"security\" + 0.006*\"our\" + 0.005*\"with\" + 0.005*\"data\" + 0.004*\"as\" + 0.004*\"or\"')\n",
      "(2, '0.013*\"that\" + 0.012*\"is\" + 0.010*\"with\" + 0.009*\"on\" + 0.009*\"as\" + 0.008*\"by\" + 0.008*\"this\" + 0.007*\"our\" + 0.006*\"security\" + 0.005*\"which\"')\n",
      "(3, '0.015*\"that\" + 0.009*\"on\" + 0.009*\"this\" + 0.009*\"is\" + 0.008*\"our\" + 0.008*\"by\" + 0.008*\"security\" + 0.006*\"with\" + 0.005*\"new\" + 0.004*\"protocol\"')\n",
      "(4, '0.007*\"that\" + 0.005*\"with\" + 0.005*\"our\" + 0.004*\"is\" + 0.004*\"on\" + 0.004*\"as\" + 0.003*\"by\" + 0.003*\"from\" + 0.003*\"show\" + 0.003*\"at\"')\n"
     ]
    }
   ],
   "source": [
    "corpus_clean = [clean_doc(doc).split() for doc in corpus]\n",
    "dictionary = corpora.Dictionary(corpus_clean)\n",
    "M1 = [dictionary.doc2bow(doc) for doc in corpus_clean]\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "lda_model = Lda(M1, num_topics=5, id2word = dictionary, passes=5,random_state =0)\n",
    "topics = lda_model.print_topics(num_topics=5, num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see in the above example, most of the topics extracted do not make sense. We can quantitatively see this also by computing the coherence score of the model. To do that, we should make a coherence model as it follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score:  0.2176289704922158\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=corpus_clean, dictionary=dictionary)\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see whether we can improve this score. As you can guess one problem is with the preprocessing step. One initial step is to extend the stopwords. We can for example use the stopwords of the english language as our stop words list. To do that one method is to use the stopwords of the nltk pacakge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let us now repeat the example with these stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.006*\"security\" + 0.005*\"data\" + 0.005*\"system\" + 0.004*\"new\" + 0.003*\"code\" + 0.003*\"model\" + 0.003*\"propose\" + 0.003*\"attacks\" + 0.003*\"existing\" + 0.003*\"show\"')\n",
      "(1, '0.007*\"security\" + 0.004*\"data\" + 0.004*\"attack\" + 0.003*\"key\" + 0.003*\"attacks\" + 0.003*\"code\" + 0.003*\"privacy\" + 0.003*\"using\" + 0.002*\"learning\" + 0.002*\"number\"')\n",
      "(2, '0.007*\"protocol\" + 0.006*\"security\" + 0.004*\"secure\" + 0.004*\"using\" + 0.003*\"show\" + 0.003*\"protocols\" + 0.003*\"new\" + 0.003*\"attacks\" + 0.003*\"also\" + 0.003*\"present\"')\n",
      "(3, '0.004*\"privacy\" + 0.004*\"new\" + 0.004*\"security\" + 0.003*\"analysis\" + 0.003*\"secure\" + 0.003*\"set\" + 0.003*\"data\" + 0.003*\"first\" + 0.003*\"workshop\" + 0.003*\"censorship\"')\n",
      "(4, '0.007*\"security\" + 0.005*\"attacks\" + 0.004*\"attack\" + 0.004*\"new\" + 0.003*\"analysis\" + 0.003*\"show\" + 0.003*\"approach\" + 0.003*\"devices\" + 0.003*\"however,\" + 0.003*\"using\"')\n"
     ]
    }
   ],
   "source": [
    "corpus_clean = [clean_doc(doc).split() for doc in corpus]\n",
    "dictionary = corpora.Dictionary(corpus_clean)\n",
    "M1 = [dictionary.doc2bow(doc) for doc in corpus_clean]\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "lda_model = Lda(M1, num_topics=5, id2word = dictionary, passes=5,random_state =0)\n",
    "topics = lda_model.print_topics(num_topics=5, num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are better now. Let us see whether the coherence score has also improved : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score:  0.2959806780538898\n"
     ]
    }
   ],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=corpus_clean, dictionary=dictionary)\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see an improvement of around 8 percent in the score. Let us see whether we can improve it more. one thing that we can do is to extend the list of stopwords as it follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stop_words)\n",
    "stop_words.update(set([\"attack\",\"new\",\"security\",\"first\",\"however\",\"ha\",\\\n",
    "                       \"protocols\",\"privacy\",\"paper\",\"also\",\"new\",\"eg\",\\\n",
    "                       \"secure\",\"system\",\"approach\",\"key\",\"using\",\"zk\",\\\n",
    "                       \"present\",\"user\",\"show\",\"attack\",\"attacks\",\"workshop\"\\\n",
    "                       \"paper\",\"et\",\"propose\",\"two\",\"per\",\"paper,\",\\\n",
    "                       \"data\",\"study\",\"al.\",\"wang\",\"zhang\",\"however,\"\n",
    "                      ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the intuition behind adding \"paper\" to the stop words is that we know that it is repeated in most of the corpus documents as it is a conference proceeding. \"Security\" has been added as it is a security conference, and many of the documents have it; therefore, it can not help in identifying the topics. More than extending the stopwords, let us also focus on another aspect of the preprocessing and see whether we can improve that part. We can add [lemmatization](https://en.wikipedia.org/wiki/Lemmatisation) to preprocessing, for which I am going to provide you a function to use it out of the box. For the lemmatization, we will use the _lemmatize_sentence_ function defined below. It is not necessary to understand the details of it at this stage, and you can use it out of the box. It is borrowed from [this page](https://gaurav5430.medium.com/using-nltk-for-lemmatizing-sentences-c1bfff963258) with a little bit of modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# function to convert nltk tag to wordnet tag\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            # lemmatized_sentence.append(word)\n",
    "            pass# This part is modified so that we will just have ADJ VERB NOUN ADVERB remained \n",
    "        else:        \n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be love\n"
     ]
    }
   ],
   "source": [
    "print(lemmatize_sentence(\"I am loving it\")) #I be love it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can modify the clean_doc function as it follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc(doc):\n",
    "    lemmatized_doc = lemmatize_sentence(doc).lower().split()\n",
    "    stop_free_lemmatized_doc = \" \".join([word for word in lemmatized_doc if (word not in stop_words and len(word) > 3)])\n",
    "    return stop_free_lemmatized_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let us see how much does it affect our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.005*\"input\" + 0.005*\"client\" + 0.005*\"proof\" + 0.005*\"browser\" + 0.005*\"message\" + 0.004*\"protocol\" + 0.004*\"model\" + 0.004*\"code\" + 0.004*\"adversarial\" + 0.004*\"allow\"')\n",
      "(1, '0.008*\"patch\" + 0.006*\"model\" + 0.006*\"protocol\" + 0.005*\"code\" + 0.005*\"skill\" + 0.004*\"group\" + 0.004*\"demonstrate\" + 0.004*\"provide\" + 0.004*\"scheme\" + 0.004*\"vulnerability\"')\n",
      "(2, '0.006*\"mechanism\" + 0.005*\"analysis\" + 0.005*\"method\" + 0.005*\"domain\" + 0.005*\"vulnerability\" + 0.004*\"e.g.\" + 0.004*\"software\" + 0.004*\"kernel\" + 0.004*\"provide\" + 0.004*\"include\"')\n",
      "(3, '0.008*\"model\" + 0.008*\"device\" + 0.005*\"contract\" + 0.004*\"distribution\" + 0.004*\"detection\" + 0.003*\"different\" + 0.003*\"large\" + 0.003*\"input\" + 0.003*\"metric\" + 0.003*\"network\"')\n",
      "(4, '0.017*\"protocol\" + 0.005*\"application\" + 0.005*\"analysis\" + 0.004*\"result\" + 0.004*\"code\" + 0.004*\"make\" + 0.004*\"technique\" + 0.004*\"work\" + 0.004*\"provide\" + 0.004*\"proof\"')\n",
      "Coherence Score:  0.30974244506568543\n"
     ]
    }
   ],
   "source": [
    "corpus_clean = [clean_doc(doc).split() for doc in corpus]\n",
    "dictionary = corpora.Dictionary(corpus_clean)\n",
    "M1 = [dictionary.doc2bow(doc) for doc in corpus_clean]\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "lda_model = Lda(M1, num_topics=5, id2word = dictionary, passes=5,random_state =0)\n",
    "topics = lda_model.print_topics(num_topics=5, num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=corpus_clean, dictionary=dictionary)\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The topics make more sense, and the coherence score has improved. One other aspect that can improve the model is to add the bigrams and even trigrams to the model. To get a notion of how this can help to enhance the model consider two documents. One with five occurrences of the \"computer science\" combination and the other one with the five repetitions of computer and science that happens separately in the text. Our current model can not make a difference between these two documents. So, let us make the bigrams and trigrams and add them to the model. For this, gensim phrases can help us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = gensim.models.Phrases(corpus_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let us see how this bigraming can affect our corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deep_neural'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(bigram[corpus_clean[8]])-set(corpus_clean[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deep', 'neural'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(corpus_clean[8])-set(bigram[corpus_clean[8]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see by using this bigram model, frequent bigrams have been detected. The same way you can make trigrams also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram = gensim.models.Phrases(bigram[corpus_clean])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us apply it to our model and see how does it affect it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.007*\"vulnerability\" + 0.007*\"protocol\" + 0.004*\"device\" + 0.004*\"exploit\" + 0.004*\"model\" + 0.004*\"technique\" + 0.004*\"base\" + 0.004*\"target\" + 0.003*\"proof\" + 0.003*\"make\"')\n",
      "(1, '0.007*\"model\" + 0.005*\"provide\" + 0.004*\"code\" + 0.004*\"large\" + 0.004*\"method\" + 0.004*\"framework\" + 0.004*\"analysis\" + 0.003*\"exist\" + 0.003*\"pets\" + 0.003*\"domain\"')\n",
      "(2, '0.005*\"analysis\" + 0.005*\"protocol\" + 0.005*\"code\" + 0.005*\"application\" + 0.004*\"scheme\" + 0.004*\"malicious\" + 0.004*\"introduce\" + 0.004*\"result\" + 0.004*\"host\" + 0.003*\"technique\"')\n",
      "(3, '0.015*\"protocol\" + 0.006*\"model\" + 0.005*\"network\" + 0.004*\"provide\" + 0.004*\"client\" + 0.004*\"device\" + 0.004*\"input\" + 0.004*\"technique\" + 0.004*\"analysis\" + 0.003*\"achieve\"')\n",
      "(4, '0.007*\"patch\" + 0.006*\"mechanism\" + 0.006*\"application\" + 0.005*\"protocol\" + 0.005*\"model\" + 0.004*\"test\" + 0.004*\"call\" + 0.003*\"cloud\" + 0.003*\"include\" + 0.003*\"base\"')\n",
      "Coherence Score:  0.31012864342450797\n"
     ]
    }
   ],
   "source": [
    "corpus_clean = [trigram[bigram[doc]] for doc in corpus_clean]\n",
    "dictionary = corpora.Dictionary(corpus_clean)\n",
    "M1 = [dictionary.doc2bow(doc) for doc in corpus_clean]\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "lda_model = Lda(M1, num_topics=5, id2word = dictionary, passes=5,random_state =0)\n",
    "topics = lda_model.print_topics(num_topics=5, num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=corpus_clean, dictionary=dictionary)\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it has been discussed in our meeting, gensim Lda can be used in multicore mode. It can save a lot of time for us while processing big datasets. The only change you need to do is instantiate the lda model from gensim.models.ldamulticore.LdaMulticore and pass the number of workers, which is the number of cpu cores which you want to use, to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, '0.007*\"algorithm\" + 0.007*\"skill\" + 0.006*\"vulnerability\" + 0.005*\"platform\" + 0.005*\"work\" + 0.004*\"model\" + 0.004*\"kernel\" + 0.004*\"verify\" + 0.004*\"database\" + 0.004*\"implement\"')\n",
      "(3, '0.014*\"protocol\" + 0.006*\"device\" + 0.006*\"setting\" + 0.005*\"technique\" + 0.005*\"design\" + 0.005*\"provide\" + 0.005*\"network\" + 0.005*\"generate\" + 0.004*\"email\" + 0.004*\"honeypot\"')\n",
      "(5, '0.006*\"software\" + 0.005*\"scheme\" + 0.005*\"provide\" + 0.005*\"base\" + 0.005*\"message\" + 0.004*\"result\" + 0.004*\"proof\" + 0.004*\"device\" + 0.004*\"vulnerability\" + 0.004*\"analysis\"')\n",
      "(9, '0.008*\"provide\" + 0.008*\"method\" + 0.007*\"model\" + 0.007*\"pets\" + 0.006*\"network\" + 0.005*\"webauthn\" + 0.005*\"service\" + 0.005*\"private\" + 0.005*\"analysis\" + 0.005*\"authenticator\"')\n",
      "(6, '0.008*\"distribution\" + 0.007*\"find\" + 0.007*\"test\" + 0.005*\"search\" + 0.005*\"utility_metric\" + 0.005*\"captcha\" + 0.005*\"developer\" + 0.005*\"efficient\" + 0.005*\"increase\" + 0.005*\"error\"')\n",
      "Coherence Score:  0.3207110052344472\n"
     ]
    }
   ],
   "source": [
    "corpus_clean = [trigram[bigram[doc]] for doc in corpus_clean]\n",
    "dictionary = corpora.Dictionary(corpus_clean)\n",
    "M1 = [dictionary.doc2bow(doc) for doc in corpus_clean]\n",
    "Lda = gensim.models.ldamulticore.LdaMulticore\n",
    "lda_model = Lda(M1, num_topics=10, id2word = dictionary, passes=10,random_state =0,workers=4)\n",
    "topics = lda_model.print_topics(num_topics=5, num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=corpus_clean, dictionary=dictionary)\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the differences in the internal  implementations of the two modes of Lda, we can expect that the results will not be the same. To continue our discussion, now let us focus on a bigger dataset which is the [20 newsgroups text dataset](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html). First let us load it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_data = fetch_20newsgroups(subset='train')\n",
    "corpus = newsgroups_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\",\n",
       " \"From: guykuo@carson.u.washington.edu (Guy Kuo)\\nSubject: SI Clock Poll - Final Call\\nSummary: Final call for SI clock reports\\nKeywords: SI,acceleration,clock,upgrade\\nArticle-I.D.: shelley.1qvfo9INNc3s\\nOrganization: University of Washington\\nLines: 11\\nNNTP-Posting-Host: carson.u.washington.edu\\n\\nA fair number of brave souls who upgraded their SI clock oscillator have\\nshared their experiences for this poll. Please send a brief message detailing\\nyour experiences with the procedure. Top speed attained, CPU rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.\\n\\nI will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven't answered this\\npoll. Thanks.\\n\\nGuy Kuo <guykuo@u.washington.edu>\\n\"]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we test our latest model on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.011*\"subject\" + 0.010*\"lines\" + 0.010*\"organization\" + 0.008*\"window\" + 0.006*\"write\" + 0.004*\"nntp-posting-host\" + 0.004*\"file\" + 0.004*\"university\" + 0.004*\"problem\" + 0.004*\"server\"')\n",
      "(1, '0.011*\"subject\" + 0.011*\"lines\" + 0.011*\"organization\" + 0.008*\"game\" + 0.007*\"team\" + 0.007*\"write\" + 0.006*\"university\" + 0.006*\"year\" + 0.006*\"article\" + 0.006*\"nntp-posting-host\"')\n",
      "(2, '0.011*\"people\" + 0.007*\"write\" + 0.007*\"think\" + 0.006*\"make\" + 0.006*\"know\" + 0.005*\"subject\" + 0.005*\"article\" + 0.005*\"right\" + 0.005*\"organization\" + 0.005*\"lines\"')\n",
      "(3, '0.009*\"chip\" + 0.009*\"drive\" + 0.008*\"encryption\" + 0.007*\"clipper\" + 0.005*\"scsi\" + 0.004*\"government\" + 0.004*\"system\" + 0.004*\"subject\" + 0.004*\"organization\" + 0.004*\"lines\"')\n",
      "(4, '0.013*\"subject\" + 0.013*\"lines\" + 0.012*\"organization\" + 0.008*\"write\" + 0.006*\"article\" + 0.006*\"university\" + 0.006*\"nntp-posting-host\" + 0.005*\"good\" + 0.005*\"know\" + 0.004*\"work\"')\n",
      "(5, '0.005*\"turkish\" + 0.004*\"armenian\" + 0.004*\"stephanopoulos\" + 0.004*\"know\" + 0.004*\"armenians\" + 0.004*\"president\" + 0.004*\"people\" + 0.003*\"work\" + 0.003*\"make\" + 0.003*\"entry\"')\n",
      "(6, '0.006*\"subject\" + 0.006*\"organization\" + 0.005*\"space\" + 0.005*\"lines\" + 0.005*\"file\" + 0.004*\"system\" + 0.004*\"write\" + 0.004*\"program\" + 0.004*\"also\" + 0.003*\"article\"')\n",
      "(7, '0.007*\"lines\" + 0.007*\"subject\" + 0.007*\"organization\" + 0.007*\"write\" + 0.005*\"article\" + 0.005*\"keith\" + 0.004*\"nntp-posting-host\" + 0.003*\"university\" + 0.003*\"livesey\" + 0.003*\"sandvik\"')\n",
      "Coherence Score:  0.501567127577859\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "corpus_clean = [clean_doc(doc).split() for doc in corpus]\n",
    "corpus_clean = [trigram[bigram[doc]] for doc in corpus_clean]\n",
    "dictionary = corpora.Dictionary(corpus_clean)\n",
    "M1 = [dictionary.doc2bow(doc) for doc in corpus_clean]\n",
    "Lda = gensim.models.ldamulticore.LdaMulticore\n",
    "lda_model = Lda(M1, num_topics=8, id2word = dictionary, passes=15,random_state =0,workers=4)\n",
    "topics = lda_model.print_topics(num_topics=8, num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=corpus_clean, dictionary=dictionary)\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result does not seem promising(E.g., \"lines\" and \"subject\" words which do not seem to be topic keywords, are repeated in multiple topics). The topics also do not make sense.  We guess that the problem is with the stop words list, and we should extend it. However, for this big data dataset, it is not easy to find all the stop words. In these cases, the [filter_extremes](https://radimrehurek.com/gensim/corpora/dictionary.html) method of the dictionary object can help us. This method, by getting the no_below and no_above parameters, can remove some of the entries from the dictionary as per the following:\n",
    "<br>filter_extremes removes all tokens in the dictionary that are:\n",
    "-  Less frequent than no_below documents (absolute number, e.g., 5) or\n",
    "-  More frequent than no_above documents (fraction of the total corpus size, e.g., 0.3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.014*\"jesus\" + 0.007*\"bible\" + 0.007*\"church\" + 0.006*\"christian\" + 0.006*\"christ\" + 0.005*\"life\" + 0.005*\"word\" + 0.005*\"love\" + 0.004*\"hell\" + 0.004*\"christians\"')\n",
      "(1, '0.010*\"israel\" + 0.008*\"president\" + 0.007*\"israeli\" + 0.005*\"government\" + 0.004*\"fire\" + 0.004*\"kill\" + 0.004*\"report\" + 0.004*\"child\" + 0.004*\"today\" + 0.004*\"talk\"')\n",
      "(2, '0.006*\"bike\" + 0.004*\"weapon\" + 0.004*\"government\" + 0.004*\"little\" + 0.003*\"power\" + 0.003*\"crime\" + 0.003*\"insurance\" + 0.003*\"keep\" + 0.003*\"firearm\" + 0.003*\"money\"')\n",
      "(3, '0.013*\"game\" + 0.012*\"team\" + 0.009*\"space\" + 0.008*\"play\" + 0.007*\"player\" + 0.005*\"hockey\" + 0.005*\"season\" + 0.004*\"league\" + 0.003*\"launch\" + 0.003*\"division\"')\n",
      "(4, '0.009*\"armenian\" + 0.008*\"armenians\" + 0.007*\"turkish\" + 0.007*\"keith\" + 0.004*\"drive\" + 0.004*\"armenia\" + 0.004*\"engine\" + 0.004*\"drug\" + 0.004*\"homosexual\" + 0.004*\"light\"')\n",
      "(5, '0.011*\"file\" + 0.008*\"drive\" + 0.007*\"program\" + 0.007*\"card\" + 0.006*\"window\" + 0.006*\"windows\" + 0.006*\"version\" + 0.006*\"software\" + 0.005*\"include\" + 0.004*\"image\"')\n",
      "(6, '0.013*\"chip\" + 0.010*\"encryption\" + 0.009*\"clipper\" + 0.007*\"government\" + 0.006*\"information\" + 0.006*\"wire\" + 0.006*\"phone\" + 0.005*\"technology\" + 0.005*\"security\" + 0.005*\"public\"')\n",
      "(7, '0.005*\"evidence\" + 0.005*\"claim\" + 0.005*\"human\" + 0.004*\"reason\" + 0.004*\"fact\" + 0.004*\"exist\" + 0.004*\"argument\" + 0.004*\"science\" + 0.003*\"life\" + 0.003*\"person\"')\n",
      "Coherence Score:  0.5170926250841685\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "corpus_clean = [clean_doc(doc).split() for doc in corpus]\n",
    "corpus_clean = [trigram[bigram[doc]] for doc in corpus_clean]\n",
    "dictionary = corpora.Dictionary(corpus_clean)\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.1) \n",
    "M1 = [dictionary.doc2bow(doc) for doc in corpus_clean]\n",
    "Lda = gensim.models.ldamulticore.LdaMulticore\n",
    "lda_model = Lda(M1, num_topics=8, id2word = dictionary, passes=15,random_state =0,workers=4)\n",
    "topics = lda_model.print_topics(num_topics=8, num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=corpus_clean, dictionary=dictionary)\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alimo21\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el275214097473083208394728996\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el275214097473083208394728996_data = {\"mdsDat\": {\"x\": [-0.18012232303379025, 0.09787571456762856, -0.042211825140108745, -0.009565125828855435, 0.0712673897797297, 0.1750177780170473, -0.11307437366855383, 0.0008127653069023821], \"y\": [0.02880004377926209, 0.0650606733939441, -0.16543172753162497, -0.040329689112933186, 0.029143481045871302, 0.03024581198481273, 0.14016048730341713, -0.08764908086274889], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [22.812735774967148, 16.297150838145523, 13.698205295353972, 11.975163871421902, 9.843306191180591, 9.379431506177228, 8.872125487179531, 7.1218810355740985]}, \"tinfo\": {\"Term\": [\"game\", \"team\", \"jesus\", \"chip\", \"file\", \"israel\", \"encryption\", \"player\", \"clipper\", \"windows\", \"space\", \"drive\", \"card\", \"bible\", \"government\", \"israeli\", \"bike\", \"armenian\", \"window\", \"president\", \"christian\", \"hockey\", \"armenians\", \"church\", \"turkish\", \"play\", \"christ\", \"season\", \"keith\", \"wire\", \"font\", \"controller\", \"scsi\", \"windows\", \"widget\", \"motherboard\", \"simms\", \"bios\", \"xterm\", \"graphic\", \"quadra\", \"jpeg\", \"x11r5\", \"vram\", \"printer\", \"polygon\", \"keyboard\", \"cursor\", \"xlib\", \"centris\", \"simm\", \"svga\", \"animation\", \"eisa\", \"ethernet\", \"desktop\", \"adaptec\", \"visual\", \"bitmap\", \"openwindows\", \"mouse\", \"interface\", \"char\", \"screen\", \"cache\", \"upgrade\", \"server\", \"window\", \"floppy\", \"card\", \"video\", \"file\", \"disk\", \"output\", \"color\", \"monitor\", \"apple\", \"format\", \"mode\", \"display\", \"port\", \"image\", \"software\", \"memory\", \"drive\", \"entry\", \"program\", \"version\", \"driver\", \"email\", \"application\", \"machine\", \"info\", \"available\", \"sale\", \"include\", \"data\", \"support\", \"line\", \"send\", \"information\", \"jake\", \"candida\", \"noring\", \"bony1.bony.com\", \"yeast\", \"fallacy\", \"livni\", \"homeopathy\", \"greeks\", \"kratz\", \"okcforum.osrhe.edu\", \"cyprus\", \"mangoe\", \"genetic\", \"o'dwyer\", \"cs.rochester.edu\", \"vice.ico.tek.com\", \"d012s658.uucp\", \"citizenship\", \"wingate\", \"cnsvax.uwec.edu\", \"quack\", \"bobbe\", \"charley\", \"arrogance\", \"beauchaine\", \"turpin\", \"horus.ap.mchp.sni.de\", \"elias\", \"nyeda\", \"theist\", \"greece\", \"methodology\", \"atheism\", \"greek\", \"atheist\", \"evidence\", \"disease\", \"patient\", \"absolute\", \"existence\", \"assertion\", \"morality\", \"objective\", \"argument\", \"human\", \"moral\", \"treatment\", \"religious\", \"militia\", \"universe\", \"religion\", \"exist\", \"belief\", \"claim\", \"minority\", \"study\", \"reason\", \"truth\", \"jews\", \"history\", \"science\", \"fact\", \"person\", \"life\", \"cause\", \"example\", \"opinion\", \"true\", \"book\", \"group\", \"word\", \"agree\", \"however\", \"wrong\", \"show\", \"anything\", \"nothing\", \"different\", \"government\", \"season\", \"hockey\", \"rangers\", \"player\", \"zoo.toronto.edu\", \"hitter\", \"spacecraft\", \"pitcher\", \"flyers\", \"mars\", \"inning\", \"phillies\", \"alomar\", \"baalke\", \"pitching\", \"nsmca\", \"sharks\", \"mets\", \"defenseman\", \"zoology\", \"kelvin.jpl.nasa.gov\", \"mail.sas.upenn.edu\", \"jays\", \"cubs\", \"venus\", \"oilers\", \"stars\", \"glutamate\", \"catcher\", \"lindros\", \"team\", \"league\", \"orbit\", \"playoff\", \"score\", \"espn\", \"lunar\", \"higgins\", \"braves\", \"leafs\", \"game\", \"maynard\", \"pens\", \"henry\", \"wings\", \"shuttle\", \"baseball\", \"moon\", \"launch\", \"coach\", \"satellite\", \"mission\", \"play\", \"toronto\", \"space\", \"roger\", \"nasa\", \"division\", \"goal\", \"boston\", \"april\", \"pittsburgh\", \"pick\", \"series\", \"center\", \"canada\", \"next\", \"david\", \"best\", \"john\", \"high\", \"second\", \"list\", \"bike\", \"behanna\", \"steveh\", \"thor.isc-br.com\", \"hendricks\", \"gnv.ifas.ufl.edu\", \"guns\", \"motorcycle\", \"broward\", \"countersteering\", \"egreen\", \"sorenson\", \"harley\", \"horne\", \"parr\", \"desire.wright.edu\", \"pa146008\", \"thomasp\", \"syl.nj.nec.com\", \"utkvm1.utk.edu\", \"ak296\", \"daker\", \"biker\", \"ifi.uio.no\", \"bikers\", \"parsli\", \"engr.latech.edu\", \"phds\", \"steam\", \"concealed\", \"veal\", \"helmet\", \"firearm\", \"ride\", \"revolver\", \"rider\", \"adobe.com\", \"libertarian\", \"homicide\", \"cunixb.cc.columbia.edu\", \"handgun\", \"insurance\", \"mccall\", \"weapon\", \"shaft\", \"east.sun.com\", \"mksol.dseg.ti.com\", \"nuclear\", \"crime\", \"iastate.edu\", \"water\", \"dare\", \"safety\", \"violent\", \"gary\", \"criminal\", \"carry\", \"rate\", \"money\", \"accident\", \"government\", \"little\", \"cool\", \"steve\", \"bill\", \"power\", \"control\", \"keep\", \"police\", \"road\", \"enough\", \"turn\", \"high\", \"sell\", \"side\", \"public\", \"cost\", \"happen\", \"course\", \"live\", \"kaldis\", \"mcovingt\", \"roby\", \"blah\", \"shai\", \"israelis\", \"magpie.linknet.com\", \"stimulus\", \"aisun3.ai.uga.edu\", \"manes\", \"laughter\", \"guday\", \"batf/fbi\", \"serbs\", \"palestinian\", \"mane\", \"murders\", \"romulus.rutgers.edu\", \"batf\", \"tclock\", \"shaig\", \"ai.uga.edu\", \"withdrawal\", \"survivors\", \"n4tmi\", \"542-0358\", \"30602-7415\", \"dividian\", \"orion.oac.uci.edu\", \"thor.ins.cwru.edu\", \"israeli\", \"senator\", \"israel\", \"iran\", \"lebanon\", \"lebanese\", \"arab\", \"waco\", \"covington\", \"intergraph\", \"president\", \"civilian\", \"territory\", \"palestinians\", \"chopin.udel.edu\", \"koresh\", \"georgia\", \"compound\", \"troop\", \"fire\", \"terrorist\", \"myers\", \"arabs\", \"secretary\", \"village\", \"border\", \"soldier\", \"press\", \"policy\", \"kill\", \"attack\", \"report\", \"today\", \"country\", \"child\", \"news\", \"government\", \"talk\", \"american\", \"force\", \"clinton\", \"group\", \"happen\", \"house\", \"center\", \"control\", \"research\", \"consider\", \"fact\", \"claim\", \"sandvik\", \"cs.pitt.edu\", \"newton.apple.com\", \"sabbath\", \"jaeger\", \"resurrection\", \"verse\", \"shameful\", \"chastity\", \"n3jxp\", \"cadre.dsl.pitt.edu\", \"qur'an\", \"jayne\", \"disciple\", \"apostle\", \"alink\", \"ksand\", \"baptism\", \"buphy.bu.edu\", \"intellect\", \"skepticism\", \"yoyo.cc.monash.edu.au\", \"jesus\", \"commandment\", \"darice\", \"cookamunga\", \"kendig\", \"salvation\", \"quack.kfu.com\", \"mlee\", \"banks\", \"christ\", \"holy\", \"mormon\", \"heaven\", \"rushdie\", \"lord\", \"gordon\", \"church\", \"scripture\", \"spirit\", \"islam\", \"father\", \"catholic\", \"kent\", \"bible\", \"prophet\", \"doctrine\", \"prophecy\", \"marriage\", \"satan\", \"christian\", \"eternal\", \"christians\", \"hell\", \"faith\", \"islamic\", \"love\", \"woman\", \"paul\", \"life\", \"word\", \"child\", \"jewish\", \"john\", \"live\", \"book\", \"true\", \"name\", \"religion\", \"hear\", \"fact\", \"encryption\", \"clipper\", \"escrow\", \"ripem\", \"privacy\", \"crypto\", \"encrypt\", \"wiretap\", \"wiring\", \"cipher\", \"key-escrow\", \"decrypt\", \"cryptography\", \"denning\", \"sternlight\", \"encrypted\", \"cryptographic\", \"plaintext\", \"sci.crypt\", \"80-bit\", \"gtoal\", \"strnlght\", \"toal\", \"nist\", \"csrc.ncsl.nist.gov\", \"templeton\", \"gtoal.com\", \"skipjack\", \"public-key\", \"dorothy\", \"outlet\", \"bontchev\", \"patent\", \"tempest\", \"wire\", \"secure\", \"vesselin\", \"amanda\", \"enforcement\", \"chip\", \"circuit\", \"algorithm\", \"security\", \"agency\", \"secret\", \"device\", \"scheme\", \"ground\", \"phone\", \"neutral\", \"communication\", \"protect\", \"technology\", \"government\", \"message\", \"public\", \"information\", \"company\", \"data\", \"provide\", \"code\", \"order\", \"access\", \"house\", \"mail\", \"cramer\", \"serdar\", \"zuma.uucp\", \"optilink\", \"wagon\", \"boyle\", \"argic\", \"ohanus\", \"sahak\", \"cactus.org\", \"melkonian\", \"appressian\", \"x-soviet\", \"mahan\", \"porsche\", \"heterosexual\", \"schneider\", \"petaluma\", \"odometer\", \"unisql.uucp\", \"detector\", \"sedan\", \"promiscuous\", \"detectors\", \"eliot\", \"bayonet\", \"taurus\", \"clayton\", \"wharfie\", \"uokmax.ecn.uoknor.edu\", \"armenian\", \"armenians\", \"serum\", \"solntze.wpd.sgi.com\", \"callison\", \"homosexual\", \"livesey\", \"radar\", \"cigarette\", \"allan\", \"armenia\", \"keith\", \"ottoman\", \"brake\", \"sensor\", \"optilink.com\", \"turkish\", \"genocide\", \"engine\", \"turks\", \"ford\", \"cco.caltech.edu\", \"drug\", \"male\", \"light\", \"road\", \"mile\", \"population\", \"drive\", \"speed\", \"show\", \"price\", \"california\", \"power\", \"cost\", \"little\", \"model\"], \"Freq\": [1770.0, 1588.0, 1254.0, 1417.0, 2699.0, 1037.0, 794.0, 925.0, 723.0, 1218.0, 1638.0, 2393.0, 1670.0, 812.0, 1872.0, 704.0, 700.0, 586.0, 1460.0, 908.0, 881.0, 695.0, 549.0, 697.0, 661.0, 1263.0, 550.0, 605.0, 536.0, 527.0, 432.93868642967004, 478.4831431787389, 613.1303852488164, 1215.1280524304673, 437.47170242591056, 251.09348638379478, 231.1631725398276, 207.69071958474257, 206.80851476276504, 506.3478692748785, 185.93700304218896, 183.0646642659922, 173.04249260260275, 163.97803343057424, 407.2671110027298, 156.1605751242425, 340.38835240257424, 136.4740484504246, 145.24722864723194, 155.15147563965758, 126.42905860281299, 117.20805464511406, 146.37578876025393, 113.23721137173125, 109.34708573548102, 132.5405965257698, 90.466291632964, 151.2936296856645, 89.43847804252536, 84.60188926744804, 506.2314805613879, 374.636788085925, 137.15661566386308, 529.2165312034115, 202.9083132454905, 335.01601551700844, 716.5792099722419, 1350.5595912493495, 310.3892352263307, 1528.8757508294384, 673.849266272418, 2374.6954359634724, 920.4741977232082, 478.0625120089532, 764.457388218459, 612.7271042546482, 535.6652916615284, 528.4332174673897, 602.7426925697803, 667.2309361092579, 477.6135700710211, 940.0129530004428, 1166.745932681117, 676.9576018424599, 1772.0822553278338, 548.4085287214923, 1565.6031727239247, 1170.5819434636708, 903.3840289867992, 872.9835722666336, 664.1165550106014, 691.5975620669517, 699.924270145444, 866.1943944818124, 689.2551409066751, 973.0128887236029, 820.6639456648993, 782.1470964511343, 755.1950977238799, 732.5080474069804, 770.4271756981275, 146.04337174746547, 86.34618663047718, 75.88627160906651, 66.77425622495389, 70.48585100906091, 67.09532620560411, 64.9937293604753, 67.9293304103175, 118.14121766678323, 60.647153204558755, 54.89123468033036, 81.42961821041034, 51.53954006769285, 64.18400993543898, 57.61741516673281, 69.91657416495171, 89.39335809408973, 52.67689992614942, 64.2273740459052, 45.77676141141398, 45.7450108066455, 49.31927566642285, 76.20597219675464, 45.17655910957757, 104.67160514685723, 75.51543823930031, 50.611859728396425, 44.49640093725907, 59.8662261443664, 36.47106031568563, 82.0241542099581, 161.8250989459617, 101.21181627181467, 216.79660551053465, 336.6299715267815, 450.9279351764967, 763.6153699288017, 303.3137292509528, 258.8913413698467, 219.2236087473603, 314.54169816089615, 102.89106950421863, 291.05369451191365, 277.64596802008214, 580.0831804373767, 679.4017056011805, 336.7295860866136, 202.08325061094965, 322.1352279241703, 214.5475004645406, 222.01941759898907, 470.7084653874985, 631.8341907688723, 364.6797040336091, 686.935895002764, 186.38918211834724, 429.9282238775534, 657.4079905749595, 374.6879300533701, 417.3338114672837, 340.693557360186, 575.25842279289, 642.5336442207288, 497.20028516778734, 507.4552828218451, 446.3010723713522, 424.7320798392197, 465.1120723651937, 437.99738946299374, 430.24644973435926, 481.1135695777854, 414.8276818960972, 352.6208647220771, 378.4194907624276, 361.5855781920848, 376.1723871369166, 369.4807255334195, 358.0373054641072, 345.0560570983668, 345.66550719177735, 603.4211286894343, 692.3763404639778, 196.80454620548798, 919.2541454002019, 137.21963435236503, 118.35092989083459, 175.61964286095574, 122.54566249476906, 142.19069544044578, 170.52540866832692, 105.88145704624202, 99.98363160312543, 98.28802034582972, 148.36394491732747, 87.4348348069936, 78.71544954582009, 82.42469093858513, 78.51624320523706, 80.96263194266264, 78.36929726357064, 115.35598773278875, 86.00428109179593, 70.7062833272719, 159.96768658771694, 92.13583587514695, 79.62150305237945, 89.791333887494, 64.759805467036, 68.69068318947153, 66.35490233573351, 1561.4967450444947, 521.0008352092361, 370.42424565128925, 268.2351632362814, 409.8020098486603, 138.58492712891845, 251.8234353524201, 108.32319746356065, 158.70409610378906, 169.76622732057513, 1654.225979561865, 141.91468852209584, 134.1273209555076, 300.9930703122102, 190.2101146572021, 215.29826404353418, 374.92122235817726, 335.5618448492292, 425.94637816522777, 167.798394205588, 296.8430796338765, 299.7114620541535, 979.3616759990626, 392.1039516037766, 1190.587008182036, 271.4355390081964, 362.9975286987126, 417.79951099722587, 323.20938424047154, 254.13068437464455, 391.0255708521097, 282.6111039921636, 268.09984547316816, 248.44350161523124, 334.07467754644335, 286.4841138184106, 316.50169600386573, 326.8592451884419, 313.890402576932, 309.6715577347285, 296.58702360055696, 291.377068372123, 291.072876401696, 699.455450337769, 100.56570876633484, 80.17882175699982, 77.58929166431894, 65.96136530145301, 71.71800231821732, 66.80273601825121, 254.82604142805516, 55.51836028071095, 52.39646281802417, 51.77135767783278, 50.438423564890165, 49.228246459305254, 47.522938996218755, 47.34142387948845, 50.76503273631967, 64.37351278019874, 42.940203152539056, 42.366141680882734, 87.52791028859464, 41.50557193970915, 41.50499142158592, 38.64456254670121, 38.86699129071628, 37.72104529036573, 37.00519549221192, 39.064796391004464, 36.28777507002472, 60.81218244883331, 40.592136348113705, 95.86528577357363, 173.59975212010886, 346.5153700821962, 308.081948427114, 88.34099042218757, 193.44948571002203, 81.07775407081665, 100.06120626624383, 139.05167376177047, 153.70660867498106, 212.47542538186806, 360.41939835281147, 69.91005602584363, 493.6913949785269, 84.89488648808131, 67.00760086393798, 60.50378542096972, 190.97735573246175, 377.5715674273112, 132.81404522890583, 242.52865511528265, 131.76178517834205, 230.96321185308003, 114.10260447541867, 214.18471584430003, 227.5592857857269, 319.5086349574626, 327.3959153908997, 336.49451784066474, 134.72602681916317, 482.4590143142237, 407.6678200038583, 147.04517611135532, 287.68659230338125, 304.8796040529507, 384.7238087135212, 325.22521622372426, 354.8898213246453, 211.59855920693522, 215.60734645748258, 293.37161918454484, 263.29048588000717, 292.4753508038935, 251.00192344270766, 239.1728991517546, 264.54035429971736, 243.12702739589943, 251.46917602989163, 243.87427032411708, 238.02148660574366, 95.38184177333586, 80.93932318610838, 140.67682704077055, 68.99531637749743, 60.4171935173726, 147.92645423332368, 59.52422369941788, 66.01404398398013, 57.48673468210875, 54.788266461926035, 70.80300977274679, 53.6033625721275, 47.74653267845846, 91.1409137832363, 162.7674064692561, 38.8821275884241, 37.66690204382053, 36.35882670383784, 175.7504614719694, 49.228094646820736, 32.60857773945411, 30.123265079501195, 32.413093463621095, 57.63663573933951, 29.46888411048054, 29.468775421212577, 29.468685288648896, 56.30823020433149, 87.77052850848168, 28.89740389238339, 669.2931153780617, 90.40878287421067, 941.7003596423662, 125.63396725836407, 160.56538310790697, 150.25642341977422, 322.8199989128103, 187.05982899396338, 82.48715379643747, 89.91975539517638, 713.2848473976705, 223.4753782408912, 141.48137151183974, 90.1593489570997, 87.61319416570507, 225.79969558540745, 217.29330234022532, 155.12076123943936, 162.39792658115445, 407.818548142555, 150.84639937013006, 108.47635364391269, 133.71351388962003, 125.62007623972633, 187.70059729491058, 168.96305527362904, 184.59929483614917, 311.8282161299004, 282.43893497889576, 397.9673770472682, 296.64348769226166, 349.68257800042863, 346.62882311996617, 328.6529542809352, 348.46839693318066, 313.9381876341547, 421.97682573734454, 343.81670834081405, 268.3357336824302, 266.993203844502, 239.2551088447898, 311.54715098485326, 277.8508693726562, 226.36568566999338, 250.92918453092585, 234.3314956097163, 234.69465561452932, 228.48358883985156, 230.5098961173489, 223.16833370984222, 216.10527520747016, 196.34780819197994, 134.53773822462273, 126.74969786192615, 101.73107831294197, 105.0704785195263, 160.78985814068702, 90.64143724130805, 88.123531971156, 86.20513421073095, 84.9839204486064, 80.78552387936239, 75.59503448053677, 69.31429581804996, 61.28222084771637, 52.96779646218698, 52.35743713196469, 54.47744736934755, 51.57242310605219, 92.04886985979026, 95.7568682150413, 48.79147233416453, 1230.04823525223, 62.84711095659735, 43.897099208472156, 42.323544820192, 41.8805854304312, 111.07165650281053, 38.571689549801505, 38.55919075841168, 285.1723031007895, 529.8837248384117, 243.4556215867124, 78.80720871154716, 249.05027057017602, 103.60785721990327, 300.45734487129795, 335.63680484444103, 602.0068638403393, 218.33044403126334, 234.3592093579878, 248.28793523244013, 301.3374133677034, 168.20695619982408, 180.39573310506853, 621.8549041509132, 120.30324159427809, 160.80483244047662, 117.11512021120906, 176.13432221690567, 145.06036662332, 545.0405049614646, 179.16125263874443, 372.5990552382817, 386.18363492458747, 338.7561475104603, 189.36174161376317, 400.5144237796249, 337.4830895295636, 345.09476254892195, 467.4848678283159, 438.76403958250137, 366.9970100419666, 250.06640109152514, 333.35406276815047, 312.1952963325399, 319.7756668007862, 313.31632778534345, 298.89971456970363, 252.78151849615298, 259.62352058961943, 248.93839779873858, 793.4970330971905, 722.6118049234243, 252.17657066331876, 252.42967539297712, 330.2009922999852, 234.13445275379036, 215.95006020466923, 182.4627809872229, 201.95715920421028, 116.82712955967035, 108.02617289398184, 97.30577019881827, 164.0808134448423, 83.60402278870683, 80.54858745128665, 68.32001718651865, 67.3555344800898, 61.425723241796824, 62.16999852539777, 57.20314077531957, 55.62579519675557, 58.168153929316425, 53.26209216086184, 50.7640329684402, 48.62130674328833, 47.53030512367873, 48.37560916435444, 45.67859868228064, 46.52482025388479, 43.73811634474812, 224.3864703633481, 102.73751506478453, 99.16183969093342, 55.080050667797906, 475.0581756126435, 299.8172805632473, 60.59466482454668, 101.3159060249041, 278.1947467034042, 1079.2906371434206, 305.18827723565914, 329.82079042150895, 437.43095861557725, 322.0103466235371, 286.11588678484793, 413.45224356193086, 148.48962135509333, 340.91243951098255, 461.517215940129, 159.17375290574165, 235.81160371485782, 282.64259257042966, 447.3470212029749, 563.403864432984, 411.80405217079254, 433.61926752561016, 510.9147873005341, 330.4237993937771, 389.5683400375576, 298.1684201391404, 286.89615126335593, 272.3295258194285, 263.657195520772, 252.44538811012683, 254.28016323861087, 226.05576870819857, 235.88468534672663, 139.40482439079042, 71.24900820723356, 71.01446321562744, 67.61121699857213, 238.38011025529426, 66.51456898067326, 64.05789988726045, 51.30552581410407, 64.04799131846455, 66.46636492512188, 58.43779265643094, 40.01160253645153, 42.47546042503411, 41.15977281044705, 103.87964764754224, 32.777089084490214, 58.201774613946924, 29.15439664732729, 183.24188251610622, 41.55708608799146, 43.30811394197878, 26.06841259917034, 42.06980369525158, 35.92664832066666, 42.91750611478483, 162.41470769475472, 22.90759449755992, 51.92507413464212, 560.8643058929422, 520.535732728912, 136.4967457607702, 129.94027302462368, 93.61088722344033, 245.5578268549164, 175.1946669472418, 188.65012743720732, 55.6556944011014, 101.72073047103557, 276.93755455856586, 437.68214478765805, 82.67776550912416, 129.54896319662072, 93.20117960374357, 88.2010464972215, 438.04295018706443, 185.74801773209862, 265.48372470319094, 220.23425629444577, 115.22992662948457, 136.20420706298665, 265.30217118248936, 140.87661703773526, 240.03632580329656, 196.53576773790172, 153.85474766614024, 162.5847836940326, 294.8702611262378, 185.24306816657744, 195.81698028660495, 169.95619113981905, 158.5488851413379, 164.865419371466, 152.72037573591507, 151.29886629445866, 145.15493986980485], \"Total\": [1770.0, 1588.0, 1254.0, 1417.0, 2699.0, 1037.0, 794.0, 925.0, 723.0, 1218.0, 1638.0, 2393.0, 1670.0, 812.0, 1872.0, 704.0, 700.0, 586.0, 1460.0, 908.0, 881.0, 695.0, 549.0, 697.0, 661.0, 1263.0, 550.0, 605.0, 536.0, 527.0, 433.9287121479547, 479.62294792807637, 614.6592529421077, 1218.8386179854506, 439.1289920084437, 252.0507928036926, 232.10164333831577, 208.60829392224923, 207.769265635803, 508.8816423787758, 186.8675508721054, 183.99238205347015, 173.96831102112955, 164.86076625139555, 409.48334985464584, 157.07127585871868, 342.5286059469036, 137.35780379086606, 146.1889518820937, 156.2522694343243, 127.39239133796931, 118.1044863309087, 147.5460830827534, 114.22044268118087, 110.32968910599736, 133.78888771546067, 91.35192563814955, 152.79311654181058, 90.33684837160433, 85.48607862376447, 511.85149781259014, 381.53876879366555, 138.85765330139978, 543.4786924396526, 206.41857199746227, 345.8245702633295, 759.6877955809691, 1460.7481989776104, 321.23015256957103, 1670.9820987474636, 722.35197554964, 2699.943568708852, 1006.6770375824215, 510.42937565220774, 839.5848593781075, 666.2009324850176, 579.7460163433275, 571.626283683801, 662.2757219105757, 744.2122899719361, 519.2760312975549, 1107.5499986493126, 1419.7898616322752, 779.08229519487, 2393.3894236997658, 618.4675931773054, 2207.8047373952068, 1553.243974178237, 1154.4688249335466, 1114.3519210350373, 818.6098709647823, 940.4195043109962, 983.7078608267925, 1458.1769212126694, 963.0369177401484, 1947.1303432596978, 1511.979858633592, 1668.304177498001, 1549.9661545552467, 1507.9854435174439, 1883.9229030676868, 147.14701516544352, 87.34374293036716, 76.77669956288706, 67.66164441200787, 71.43957891045709, 68.0088766443051, 65.8805139247221, 68.86233521545759, 119.81300169768697, 61.54690989940547, 55.7853222264881, 82.8274716424737, 52.4381153010915, 65.32435575129065, 58.64604805121581, 71.20512739478808, 91.08058919550761, 53.6782921977062, 65.4762156971967, 46.68517397147493, 46.658215090909, 50.324008028498284, 77.7939197643264, 46.14751759018031, 106.96050911224549, 77.17269925506844, 51.728447973686464, 45.52196030253571, 61.258435379404396, 37.3672764616916, 84.5742379069631, 168.35742117715952, 104.66571035789751, 228.16387028999137, 363.5817954922876, 501.952029460432, 869.546600090814, 333.745688108777, 284.79605547120264, 244.85738832664117, 372.9435792937967, 110.37601650941593, 347.10177455484256, 341.3587156457955, 790.672326890886, 988.1672726540322, 448.13791703632813, 246.59791020198514, 433.96190863207244, 268.05838927080714, 289.95752695705835, 734.4584986471193, 1072.526327943062, 567.4143961146843, 1299.1095581472393, 248.46126264541687, 768.5318640429006, 1444.969165709737, 680.6854867952605, 796.4568551060661, 608.1917305825305, 1354.7729092327995, 1660.9736829053293, 1164.0139869181467, 1399.4124530857982, 1113.4628231578583, 1121.5982893106482, 1367.4094170899841, 1341.0463298333657, 1296.5437842344966, 1877.240452713373, 1308.9388456504503, 853.320626219298, 1450.6247590691742, 1071.26646330765, 1507.6729886592957, 1477.5008248175436, 1130.0361374589781, 1330.7074065272002, 1872.419904695101, 605.0384427721173, 695.4440700398915, 198.07830893487338, 925.5864354563815, 138.2220545701029, 119.27715590702248, 177.01309762468125, 123.5194203396166, 143.3445196181542, 172.03465843182653, 106.81865388325204, 100.9136854327322, 99.24458404293955, 149.87011008473962, 88.34821544101246, 79.62030032327446, 83.37280127340453, 79.43532806907056, 81.9185225836514, 79.3122962205233, 116.748583279139, 87.05770334156753, 71.6175327838476, 162.03277276690724, 93.32916765471849, 80.67813735634921, 90.99156910572731, 65.66060113414191, 69.67090600066662, 67.30256806888649, 1588.1657197341583, 528.5043830434004, 375.95629222401635, 272.17300138387986, 420.1108846229197, 140.685517797047, 257.73093861502974, 109.9282731665282, 161.7143580363285, 173.2897282701843, 1770.363359712489, 144.56002320472214, 137.0182279305456, 315.6898263638735, 196.8251337835197, 225.629797970232, 405.73074711624866, 367.07390169251335, 479.04650706114694, 174.79108718212683, 329.5591751548298, 333.2858845207165, 1263.5039358908823, 451.85992958232754, 1638.763922876369, 302.3149248154962, 482.17988958349883, 636.5919592772714, 497.95553140087026, 339.3388395672931, 712.6996855007162, 487.3129138207292, 508.3670734586262, 443.42140554043596, 1178.0258654934878, 727.1519173529209, 1039.4432877775826, 1586.6142173102942, 1317.9493761219155, 1364.4718126874268, 1475.6000727438686, 1266.1244705868946, 1397.575669721073, 700.707221602929, 101.45820624607057, 81.11329028584584, 78.50713488218383, 66.88769502619904, 72.73916966429746, 67.76280055729708, 258.83576675148635, 56.40841240350469, 53.302801464724105, 52.67356154264347, 51.36426641441863, 50.141881257211395, 48.41382005736917, 48.25170445161201, 51.811734640320125, 65.70515762858966, 43.83228234590606, 43.251449866130244, 89.39124375183604, 42.401704354251294, 42.40168934587946, 39.540855103274566, 39.77776778855025, 38.6141344673224, 37.898881937726046, 40.03543120104794, 37.25196531047306, 62.43129973619415, 41.67372231846536, 98.46322227417795, 179.55670182519023, 360.93009430734963, 322.72766853157367, 91.41011801063438, 203.90889628218514, 84.91981699904977, 105.74314645324807, 150.4881699779359, 167.5894978000379, 237.83991896875966, 419.0852087528332, 73.55279741356776, 651.7647861346238, 93.15720927810845, 71.3555597872989, 63.46141574981073, 259.4637694942133, 635.9876538715935, 170.17402532390935, 402.5254245110538, 177.17526943552528, 384.16024287466115, 146.33582514115432, 367.9461292495198, 413.55798765689184, 699.6856649945756, 729.5717641027724, 835.3620690931905, 197.4141741128468, 1872.419904695101, 1504.0920844984962, 233.46138330578214, 841.8145080707495, 952.9002140176644, 1583.867362436942, 1209.1228083017184, 1586.7832708083554, 528.8893140598095, 556.8078103440231, 1274.724312792362, 984.3729602759163, 1475.6000727438686, 918.4790058417801, 829.5598713384733, 1342.277672542913, 922.2390043531793, 1318.2191573020434, 1347.836815499997, 1140.3128207337215, 96.31219499241438, 81.85222289029569, 142.41696706248007, 69.97627787700667, 61.32303490430656, 150.14792633948224, 60.428350756265466, 67.02664291440146, 58.38925806714051, 55.675743219315656, 71.95031593696483, 54.508707558007764, 48.73575464660908, 93.1644332819939, 166.39923008531645, 39.767872717852256, 38.56116808017254, 37.2464532016186, 180.2067932546264, 50.50803848435414, 33.49742647935126, 31.009483731432912, 33.38153029276685, 59.36331472185716, 30.354202686507303, 30.354187593519487, 30.354185474025673, 58.05139004127283, 90.56401992409849, 29.932394408750884, 704.6161425298067, 94.82049191350687, 1037.0406476599073, 132.8910121989676, 172.51321536094085, 161.68138100630577, 359.557017118071, 204.85299160046847, 88.22940691079911, 97.54415429566451, 908.2403543161603, 260.13478172936726, 162.61215715304238, 98.17912069358765, 95.46189815515119, 289.6297479756209, 282.19495910993857, 192.69800563465432, 204.94680997137206, 700.2288435521208, 196.78763241031112, 126.97798394887779, 168.39387945792262, 157.54804938101293, 277.8443915803614, 242.84905668256624, 287.35773668235197, 665.9450826153643, 572.0226202253376, 1121.6897552786825, 682.8209143051494, 925.1785007653447, 929.9535572430201, 870.3453301915505, 1099.1780201379638, 920.1775810707543, 1872.419904695101, 1331.4504168399574, 831.2958803948252, 823.9299882266979, 612.1331989163951, 1877.240452713373, 1318.2191573020434, 741.3112225232885, 1178.0258654934878, 1209.1228083017184, 1291.5719466457108, 1394.9820174432375, 1660.9736829053293, 1299.1095581472393, 217.0260823784952, 197.40083333127353, 135.4427114173509, 127.69348232595902, 102.64771939880768, 106.03199720543913, 162.26865924597746, 91.54503619493535, 89.02115211612225, 87.10418675250364, 85.88050134007455, 81.67754036729214, 76.53670972440327, 70.22524671429287, 62.18852137955184, 53.860345940389585, 53.24956701730219, 55.40789625306339, 52.472893232402846, 93.861315933589, 97.66182222058494, 49.7645736030001, 1254.668489628069, 64.10628996208784, 44.79981028826744, 43.21459680722212, 42.80636003247822, 113.55344134759716, 39.46044751477766, 39.45390804843673, 291.8985014879407, 550.8293440016378, 254.0005606262314, 81.07819116064412, 262.7466717096137, 107.44729250696908, 324.813723456974, 368.9543390503641, 697.165856540922, 239.6957211025994, 259.1199306054593, 276.8483135775086, 343.4559646921119, 183.5417086595716, 199.4050588609461, 812.104904424016, 128.39300797727688, 182.54388708782278, 125.77945458183373, 207.53511837652687, 164.83667140254758, 881.0483053899651, 219.9969541994135, 578.6439206417474, 658.7187795609113, 575.3245770823393, 250.55361950574783, 809.9010100983915, 678.2972898748815, 735.9457153327584, 1399.4124530857982, 1308.9388456504503, 1099.1780201379638, 522.8378645046515, 1364.4718126874268, 1140.3128207337215, 1296.5437842344966, 1341.0463298333657, 1532.4942054246317, 734.4584986471193, 1394.6088803026269, 1660.9736829053293, 794.5579892669125, 723.9789276357773, 253.11727484211914, 253.39616451606088, 331.48332739760366, 235.120290430471, 216.90532778369192, 183.39794527129962, 203.1048109409338, 117.76893207936335, 108.93715302222904, 98.21879355837584, 165.8507567764732, 84.51284709884305, 81.56349905386571, 69.22446306597116, 68.32166691180275, 62.333433949925784, 63.091884618856724, 58.116695636907544, 56.544230245233635, 59.14660784622984, 54.17987430821206, 51.689093360346924, 49.53064568003847, 48.426984958721086, 49.29525533833242, 46.576333688300814, 47.44691402999693, 44.642699760040195, 229.74537396351857, 105.33770242877208, 103.26499907221212, 56.366205721624816, 527.4267709123183, 334.8486040091993, 62.304824952691945, 107.3790757312089, 315.47234021206515, 1417.5652971455224, 360.8036629753395, 431.17826759960707, 603.5026005845476, 426.9643674043233, 391.01179207863265, 716.2761802055434, 189.4665622012932, 611.6622584467209, 1003.2452559512507, 215.0078173907459, 398.74488525247733, 566.9679910193851, 1219.3935303343005, 1872.419904695101, 1217.9120175364867, 1342.277672542913, 1883.9229030676868, 897.0374296076178, 1511.979858633592, 1240.0922960231153, 1033.62570854653, 1265.1001792689804, 1018.4618659018655, 741.3112225232885, 959.4142106565265, 226.97382563718662, 238.36498570134913, 141.00952753326538, 72.14308686619107, 71.92759700662184, 68.52585992940004, 241.77660210195097, 67.66508998321895, 65.19544149899312, 52.22274403066868, 65.19641371632262, 67.66567420759755, 59.616021783397535, 40.90005915091478, 43.41915623248544, 42.08693164034924, 106.40941322277715, 33.66637272570169, 59.84333686955177, 30.04403350005234, 188.85035609446084, 42.90242432270236, 44.76443848545214, 26.955574767471056, 43.56558097103769, 37.20412491642948, 44.4796254168733, 168.55059408042723, 23.796823991972577, 54.10019827657728, 586.8393003757777, 549.2570169570171, 142.87185242979314, 136.39809536119364, 98.51903328919322, 271.4649002792205, 191.9607890034096, 210.19723322587694, 58.275429311317254, 110.22327179495005, 326.77122452383355, 536.0385115908022, 89.54111891022622, 146.6905662970709, 103.36148595848857, 98.02154261484985, 661.9971320692579, 249.63029807554508, 418.3933992043078, 333.68681071300335, 141.7023661314044, 191.81714319598558, 599.5153577618927, 217.81317193995432, 686.257973888376, 556.8078103440231, 329.1576570038173, 412.456739239641, 2393.3894236997658, 813.2689358490508, 1507.6729886592957, 1003.4287641919809, 628.976862655063, 1583.867362436942, 922.2390043531793, 1504.0920844984962, 679.9992054417007], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.189499855041504, -6.0894999504089355, -5.8414998054504395, -5.15749979019165, -6.179100036621094, -6.734300136566162, -6.816999912261963, -6.923999786376953, -6.928299903869629, -6.032899856567383, -7.0346999168396, -7.05019998550415, -7.106599807739258, -7.160399913787842, -6.2505998611450195, -7.209199905395508, -6.429999828338623, -7.343999862670898, -7.281700134277344, -7.215700149536133, -7.420400142669678, -7.496099948883057, -7.273900032043457, -7.530600070953369, -7.5655999183654785, -7.373199939727783, -7.755099773406982, -7.240900039672852, -7.766499996185303, -7.8221001625061035, -6.033100128173828, -6.334099769592285, -7.339000225067139, -5.988699913024902, -6.947299957275391, -6.445899963378906, -5.6855998039245605, -5.051799774169922, -6.522299766540527, -4.927800178527832, -5.747099876403809, -4.487500190734863, -5.435200214385986, -6.0903000831604, -5.6209001541137695, -5.842199802398682, -5.976600170135498, -5.990200042724609, -5.85860013961792, -5.756999969482422, -6.091300010681152, -5.4141998291015625, -5.1981000900268555, -5.742499828338623, -4.780200004577637, -5.953100204467773, -4.904099941253662, -5.194799900054932, -5.45389986038208, -5.4882001876831055, -5.761600017547607, -5.721099853515625, -5.709099769592285, -5.495999813079834, -5.7245001792907715, -5.379700183868408, -5.550000190734863, -5.5980000495910645, -5.6331000328063965, -5.663599967956543, -5.613100051879883, -6.939899921417236, -7.465400218963623, -7.5945000648498535, -7.722400188446045, -7.668300151824951, -7.717599868774414, -7.749499797821045, -7.7052998542785645, -7.151899814605713, -7.818699836730957, -7.918399810791016, -7.52400016784668, -7.981400012969971, -7.76200008392334, -7.869900226593018, -7.676499843597412, -7.430699825286865, -7.95959997177124, -7.761300086975098, -8.100000381469727, -8.100700378417969, -8.025400161743164, -7.5903000831604, -8.113200187683105, -7.272900104522705, -7.599400043487549, -7.999599933624268, -8.128399848937988, -7.831600189208984, -8.327199935913086, -7.51669979095459, -6.837200164794922, -7.30649995803833, -6.5447998046875, -6.104800224304199, -5.8125, -5.285699844360352, -6.209000110626221, -6.367400169372559, -6.533699989318848, -6.172599792480469, -7.29010009765625, -6.25029993057251, -6.297399997711182, -5.5605998039245605, -5.402500152587891, -6.104499816894531, -6.615099906921387, -6.148799896240234, -6.555200099945068, -6.520999908447266, -5.769499778747559, -5.475100040435791, -6.024700164794922, -5.391499996185303, -6.695899963378906, -5.860099792480469, -5.435500144958496, -5.997700214385986, -5.889900207519531, -6.092800140380859, -5.568900108337402, -5.4583001136779785, -5.714799880981445, -5.694399833679199, -5.822800159454346, -5.872300148010254, -5.781499862670898, -5.8414998054504395, -5.859399795532227, -5.747700214385986, -5.895899772644043, -6.0584001541137695, -5.987800121307373, -6.033299922943115, -5.99370002746582, -6.01170015335083, -6.043099880218506, -6.080100059509277, -6.0782999992370605, -5.347400188446045, -5.20989990234375, -6.467800140380859, -4.926499843597412, -6.828499794006348, -6.976399898529053, -6.581699848175049, -6.9415998458862305, -6.792900085449219, -6.611199855804443, -7.087699890136719, -7.144999980926514, -7.162099838256836, -6.750400066375732, -7.279099941253662, -7.384200096130371, -7.338200092315674, -7.38670015335083, -7.355999946594238, -7.388599872589111, -7.001999855041504, -7.295599937438965, -7.491499900817871, -6.675099849700928, -7.226799964904785, -7.372799873352051, -7.252500057220459, -7.579400062561035, -7.520400047302246, -7.554999828338623, -4.396599769592285, -5.49429988861084, -5.835400104522705, -6.158199787139893, -5.734399795532227, -6.818600177764893, -6.22130012512207, -7.064899921417236, -6.683000087738037, -6.615600109100342, -4.338900089263916, -6.7947998046875, -6.851200103759766, -6.042900085449219, -6.5019001960754395, -6.377999782562256, -5.823299884796143, -5.934199810028076, -5.695700168609619, -6.627299785614014, -6.05679988861084, -6.0472002029418945, -4.863100051879883, -5.778500080108643, -4.667799949645996, -6.146299839019775, -5.855599880218506, -5.715000152587891, -5.971700191497803, -6.212200164794922, -5.781300067901611, -6.105999946594238, -6.158699989318848, -6.234799861907959, -5.938700199127197, -6.092400074005127, -5.992700099945068, -5.9604997634887695, -6.000999927520752, -6.014500141143799, -6.057700157165527, -6.075399875640869, -6.076499938964844, -5.065299987792969, -7.004799842834473, -7.231299877166748, -7.264200210571289, -7.426499843597412, -7.342899799346924, -7.413899898529053, -6.074999809265137, -7.598899841308594, -7.656799793243408, -7.668799877166748, -7.694900035858154, -7.719099998474121, -7.75439977645874, -7.758200168609619, -7.688399791717529, -7.450900077819824, -7.855800151824951, -7.86929988861084, -7.143599987030029, -7.889800071716309, -7.889800071716309, -7.96120023727417, -7.95550012588501, -7.985400199890137, -8.004500389099121, -7.950399875640869, -8.024100303649902, -7.507800102233887, -7.9120001792907715, -7.052700042724609, -6.458899974822998, -5.7677001953125, -5.885200023651123, -7.134399890899658, -6.350599765777588, -7.220200061798096, -7.009799957275391, -6.680799961090088, -6.580599784851074, -6.256800174713135, -5.728300094604492, -7.3684000968933105, -5.413700103759766, -7.174200057983398, -7.410799980163574, -7.512899875640869, -6.363399982452393, -5.68179988861084, -6.7266998291015625, -6.124499797821045, -6.734600067138672, -6.173299789428711, -6.878499984741211, -6.248799800872803, -6.188199996948242, -5.848800182342529, -5.824399948120117, -5.796999931335449, -6.712399959564209, -5.436699867248535, -5.605199813842773, -6.624899864196777, -5.953700065612793, -5.895699977874756, -5.663099765777588, -5.831099987030029, -5.743800163269043, -6.260900020599365, -6.242099761962891, -5.934199810028076, -6.042300224304199, -5.93720006942749, -6.090099811553955, -6.138400077819824, -6.037600040435791, -6.122000217437744, -6.0883002281188965, -6.11899995803833, -6.143199920654297, -6.861700057983398, -7.025899887084961, -6.473100185394287, -7.185500144958496, -7.318299770355225, -6.422800064086914, -7.333199977874756, -7.229700088500977, -7.368000030517578, -7.416100025177002, -7.1596999168396, -7.438000202178955, -7.553699970245361, -6.907199859619141, -6.327199935913086, -7.758999824523926, -7.790800094604492, -7.826099872589111, -6.250500202178955, -7.523099899291992, -7.934999942779541, -8.014300346374512, -7.940999984741211, -7.3653998374938965, -8.036199569702148, -8.036199569702148, -8.036199569702148, -7.388700008392334, -6.944799900054932, -8.055800437927246, -4.913300037384033, -6.915200233459473, -4.571899890899658, -6.58620023727417, -6.34089994430542, -6.407199859619141, -5.642499923706055, -6.1880998611450195, -7.006899833679199, -6.920599937438965, -4.849699974060059, -6.010300159454346, -6.467400074005127, -6.918000221252441, -6.946599960327148, -5.999899864196777, -6.038300037384033, -6.375400066375732, -6.329500198364258, -5.408699989318848, -6.403299808502197, -6.732999801635742, -6.523900032043457, -6.586299896240234, -6.184700012207031, -6.289899826049805, -6.201399803161621, -5.67710018157959, -5.776100158691406, -5.433199882507324, -5.7270002365112305, -5.5625, -5.571300029754639, -5.624599933624268, -5.565999984741211, -5.670400142669678, -5.374599933624268, -5.579500198364258, -5.827300071716309, -5.832300186157227, -5.941999912261963, -5.677999973297119, -5.792500019073486, -5.997399806976318, -5.894400119781494, -5.962800025939941, -5.961299896240234, -5.988100051879883, -5.979300022125244, -6.011600017547607, -5.995500087738037, -6.091400146484375, -6.469399929046631, -6.529099941253662, -6.749000072479248, -6.716700077056885, -6.291200160980225, -6.8643999099731445, -6.892499923706055, -6.914599895477295, -6.928800106048584, -6.979499816894531, -7.045899868011475, -7.132599830627441, -7.255799770355225, -7.401599884033203, -7.4131999015808105, -7.373499870300293, -7.428299903869629, -6.848999977111816, -6.809500217437744, -7.483699798583984, -4.256499767303467, -7.230599880218506, -7.589399814605713, -7.625899791717529, -7.636499881744385, -6.661099910736084, -7.718800067901611, -7.719099998474121, -5.718200206756592, -5.098599910736084, -5.876399993896484, -7.004300117492676, -5.853600025177002, -6.7307000160217285, -5.665999889373779, -5.555300235748291, -4.9710001945495605, -5.985300064086914, -5.914400100708008, -5.8566999435424805, -5.663099765777588, -6.246099948883057, -6.17609977722168, -4.938600063323975, -6.581299781799316, -6.291100025177002, -6.608099937438965, -6.199999809265137, -6.394100189208984, -5.070400238037109, -6.183000087738037, -5.450799942016602, -5.414999961853027, -5.546000003814697, -6.127600193023682, -5.378499984741211, -5.549799919128418, -5.527500152587891, -5.223899841308594, -5.287300109863281, -5.46589994430542, -5.849599838256836, -5.562099933624268, -5.627699851989746, -5.603700160980225, -5.624100208282471, -5.671199798583984, -5.838799953460693, -5.812099933624268, -5.854100227355957, -4.639200210571289, -4.732800006866455, -5.785600185394287, -5.784599781036377, -5.515999794006348, -5.859799861907959, -5.9405999183654785, -6.109099864959717, -6.007599830627441, -6.554999828338623, -6.633299827575684, -6.737800121307373, -6.2153000831604, -6.889599800109863, -6.926799774169922, -7.0914998054504395, -7.1057000160217285, -7.19789981842041, -7.185800075531006, -7.269100189208984, -7.296999931335449, -7.252299785614014, -7.3404998779296875, -7.388500213623047, -7.431600093841553, -7.4542999267578125, -7.436699867248535, -7.494100093841553, -7.4756999015808105, -7.537499904632568, -5.902299880981445, -6.683499813079834, -6.718900203704834, -7.3069000244140625, -5.152200222015381, -5.612500190734863, -7.21150016784668, -6.697400093078613, -5.687399864196777, -4.331600189208984, -5.594799995422363, -5.517099857330322, -5.234799861907959, -5.541100025177002, -5.659299850463867, -5.291100025177002, -6.315199851989746, -5.484099864959717, -5.18120002746582, -6.245699882507324, -5.852700233459473, -5.671500205993652, -5.212399959564209, -4.9816999435424805, -5.295100212097168, -5.243500232696533, -5.079500198364258, -5.5152997970581055, -5.350599765777588, -5.618000030517578, -5.656599998474121, -5.708700180053711, -5.741000175476074, -5.7845001220703125, -5.777200222015381, -5.67519998550415, -5.632599830627441, -6.158599853515625, -6.829800128936768, -6.833099842071533, -6.882199764251709, -5.622099876403809, -6.898499965667725, -6.936200141906738, -7.158100128173828, -6.936299800872803, -6.899199962615967, -7.0279998779296875, -7.406799793243408, -7.3470001220703125, -7.378499984741211, -6.452700138092041, -7.606200218200684, -7.0320000648498535, -7.723299980163574, -5.8850998878479, -7.368899822235107, -7.327600002288818, -7.83519983291626, -7.356599807739258, -7.514500141143799, -7.336699962615967, -6.005799770355225, -7.9644999504089355, -7.146100044250488, -4.766499996185303, -4.841100215911865, -6.179599761962891, -6.228899955749512, -6.55679988861084, -5.592400074005127, -5.929999828338623, -5.855999946594238, -7.0767998695373535, -6.473700046539307, -5.4721999168396, -5.014400005340576, -6.681000232696533, -6.231900215148926, -6.561200141906738, -6.616300106048584, -5.013599872589111, -5.871600151062012, -5.514400005340576, -5.701200008392334, -6.348999977111816, -6.18179988861084, -5.515100002288818, -6.148099899291992, -5.615200042724609, -5.815100193023682, -6.059899806976318, -6.004700183868408, -5.40939998626709, -5.874300003051758, -5.81879997253418, -5.960400104522705, -6.029900074005127, -5.990799903869629, -6.067299842834473, -6.076700210571289, -6.118100166320801], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.4756, 1.4755, 1.4754, 1.4748, 1.4741, 1.474, 1.4738, 1.4734, 1.4732, 1.4729, 1.4729, 1.4728, 1.4725, 1.4725, 1.4724, 1.472, 1.4716, 1.4714, 1.4714, 1.4708, 1.4703, 1.4702, 1.4699, 1.4692, 1.4689, 1.4685, 1.4681, 1.468, 1.4679, 1.4675, 1.4668, 1.4596, 1.4655, 1.4513, 1.4607, 1.4461, 1.4194, 1.3994, 1.4435, 1.389, 1.4083, 1.3495, 1.3883, 1.4123, 1.3841, 1.3942, 1.3988, 1.3993, 1.3837, 1.3687, 1.3942, 1.3138, 1.2816, 1.3373, 1.1773, 1.3576, 1.1341, 1.195, 1.2326, 1.2337, 1.2687, 1.1705, 1.1375, 0.957, 1.1434, 0.7841, 0.8668, 0.7203, 0.7588, 0.7558, 0.5837, 1.8067, 1.8027, 1.8025, 1.801, 1.8007, 1.8007, 1.8006, 1.8005, 1.8001, 1.7995, 1.798, 1.7972, 1.7969, 1.7966, 1.7965, 1.7959, 1.7955, 1.7953, 1.7949, 1.7945, 1.7944, 1.794, 1.7936, 1.7929, 1.7925, 1.7925, 1.7924, 1.7914, 1.7912, 1.7899, 1.7836, 1.7746, 1.7806, 1.7631, 1.7372, 1.707, 1.6843, 1.7186, 1.7188, 1.7036, 1.6439, 1.744, 1.6381, 1.6076, 1.5045, 1.4395, 1.5284, 1.6151, 1.5162, 1.5915, 1.5472, 1.3693, 1.285, 1.3721, 1.177, 1.5267, 1.2333, 1.0266, 1.2172, 1.1679, 1.2347, 0.9576, 0.8644, 0.9635, 0.7998, 0.8999, 0.8431, 0.7358, 0.6952, 0.7111, 0.4527, 0.6651, 0.9304, 0.4704, 0.7281, 0.4259, 0.4282, 0.6648, 0.4644, 0.1247, 1.9852, 1.9835, 1.9815, 1.981, 1.9806, 1.9801, 1.98, 1.98, 1.9798, 1.9791, 1.9791, 1.9786, 1.9782, 1.9778, 1.9775, 1.9765, 1.9765, 1.9763, 1.9762, 1.9759, 1.9759, 1.9757, 1.9751, 1.9751, 1.975, 1.9747, 1.9746, 1.9741, 1.9737, 1.9737, 1.971, 1.9736, 1.9731, 1.9733, 1.9631, 1.9729, 1.9647, 1.9732, 1.9691, 1.9674, 1.9201, 1.9694, 1.9666, 1.9402, 1.9537, 1.941, 1.9089, 1.8981, 1.8704, 1.9471, 1.8834, 1.8817, 1.7332, 1.8461, 1.6684, 1.8802, 1.704, 1.5668, 1.5557, 1.6988, 1.3876, 1.4431, 1.3481, 1.4086, 0.7277, 1.0565, 0.7988, 0.4081, 0.5531, 0.5049, 0.3834, 0.5188, 0.419, 2.1205, 2.1135, 2.1107, 2.1106, 2.1084, 2.1082, 2.1081, 2.1067, 2.1064, 2.1052, 2.1051, 2.1041, 2.1039, 2.1038, 2.1033, 2.1019, 2.1019, 2.1018, 2.1017, 2.1013, 2.101, 2.101, 2.0994, 2.0992, 2.0989, 2.0985, 2.0978, 2.0961, 2.0961, 2.096, 2.0956, 2.0886, 2.0816, 2.0759, 2.0882, 2.0697, 2.076, 2.0671, 2.0433, 2.0359, 2.0096, 1.9715, 2.0715, 1.8446, 2.0295, 2.0595, 2.0746, 1.8159, 1.6009, 1.8745, 1.6157, 1.8262, 1.6135, 1.8735, 1.5812, 1.5249, 1.3385, 1.321, 1.2131, 1.7403, 0.7662, 0.8168, 1.6601, 1.0486, 0.9827, 0.7072, 0.8092, 0.6247, 1.2062, 1.1736, 0.6533, 0.8036, 0.5039, 0.8251, 0.8786, 0.4982, 0.7891, 0.4656, 0.4127, 0.5556, 2.3087, 2.3072, 2.3061, 2.3043, 2.3035, 2.3035, 2.3033, 2.3032, 2.3028, 2.3023, 2.3023, 2.3016, 2.2979, 2.2964, 2.2963, 2.2959, 2.2949, 2.2943, 2.2933, 2.2927, 2.2915, 2.2894, 2.2889, 2.2889, 2.2888, 2.2888, 2.2888, 2.2879, 2.287, 2.2832, 2.2669, 2.2707, 2.2219, 2.2622, 2.2466, 2.2451, 2.2106, 2.2275, 2.2511, 2.237, 2.0768, 2.1665, 2.1792, 2.2332, 2.2326, 2.0694, 2.057, 2.1015, 2.0857, 1.7778, 2.0525, 2.1609, 2.0878, 2.0919, 1.9262, 1.9556, 1.8758, 1.5596, 1.6127, 1.2822, 1.4847, 1.3454, 1.3315, 1.3445, 1.1696, 1.243, 0.8283, 0.9645, 1.1876, 1.1915, 1.379, 0.5224, 0.7614, 1.1321, 0.772, 0.6775, 0.613, 0.5092, 0.3435, 0.5569, 2.3624, 2.3613, 2.3599, 2.3592, 2.3577, 2.3575, 2.3575, 2.3567, 2.3565, 2.3563, 2.3562, 2.3557, 2.3543, 2.3536, 2.352, 2.3499, 2.3498, 2.3497, 2.3493, 2.3472, 2.347, 2.3469, 2.3468, 2.3468, 2.3463, 2.3458, 2.3448, 2.3446, 2.3439, 2.3437, 2.3433, 2.3279, 2.3242, 2.3382, 2.3131, 2.3303, 2.2887, 2.272, 2.2199, 2.2733, 2.2662, 2.2578, 2.2358, 2.2794, 2.2665, 2.0997, 2.3016, 2.2399, 2.2953, 2.2026, 2.2388, 1.8864, 2.1613, 1.9265, 1.8327, 1.837, 2.0866, 1.6625, 1.6686, 1.6093, 1.2702, 1.2736, 1.2697, 1.6291, 0.9573, 1.0712, 0.9668, 0.9127, 0.7321, 1.3, 0.6855, 0.4687, 2.4209, 2.4204, 2.4185, 2.4184, 2.4184, 2.4181, 2.4178, 2.4171, 2.4166, 2.4142, 2.4139, 2.4129, 2.4115, 2.4114, 2.4097, 2.4091, 2.408, 2.4076, 2.4075, 2.4064, 2.4059, 2.4056, 2.4052, 2.4042, 2.4037, 2.4036, 2.4034, 2.4028, 2.4026, 2.4018, 2.3987, 2.3973, 2.3817, 2.3992, 2.3177, 2.3118, 2.3944, 2.3641, 2.2965, 2.1496, 2.2549, 2.1543, 2.1004, 2.1401, 2.1099, 1.8727, 2.1786, 1.8377, 1.6458, 2.1216, 1.897, 1.7261, 1.4195, 1.2213, 1.3379, 1.2923, 1.1173, 1.4235, 1.0661, 0.997, 1.1405, 0.8864, 1.0709, 1.345, 1.0944, 2.6379, 2.6315, 2.6306, 2.6295, 2.6292, 2.6286, 2.6279, 2.6248, 2.6244, 2.6243, 2.6242, 2.6241, 2.622, 2.62, 2.62, 2.6197, 2.6179, 2.6152, 2.6142, 2.6119, 2.6119, 2.6101, 2.6089, 2.6085, 2.6071, 2.6071, 2.6062, 2.6049, 2.6039, 2.601, 2.5967, 2.5883, 2.5964, 2.5935, 2.5909, 2.5417, 2.5506, 2.5338, 2.596, 2.5617, 2.4765, 2.4393, 2.5623, 2.5177, 2.5385, 2.5364, 2.2291, 2.3464, 2.1871, 2.2265, 2.4352, 2.2996, 1.8267, 2.2062, 1.5915, 1.6006, 1.8815, 1.7111, 0.5481, 1.1626, 0.6009, 0.8664, 1.264, 0.3795, 0.8438, 0.3453, 1.0977]}, \"token.table\": {\"Topic\": [5, 5, 7, 1, 2, 3, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 2, 3, 4, 5, 6, 8, 1, 1, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 5, 5, 4, 1, 3, 7, 6, 2, 3, 8, 3, 1, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 1, 2, 3, 4, 5, 6, 7, 8, 6, 1, 2, 3, 4, 5, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 8, 1, 2, 3, 4, 5, 6, 7, 8, 2, 5, 6, 2, 5, 6, 2, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 5, 8, 1, 2, 5, 6, 8, 1, 2, 5, 6, 8, 2, 6, 2, 4, 5, 6, 8, 2, 6, 2, 6, 2, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 3, 5, 2, 3, 6, 6, 3, 4, 5, 6, 5, 7, 5, 5, 8, 2, 8, 4, 2, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 5, 6, 4, 4, 4, 1, 2, 3, 4, 5, 6, 7, 8, 1, 1, 5, 2, 8, 4, 7, 2, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 8, 3, 4, 8, 3, 4, 4, 6, 1, 8, 8, 6, 1, 2, 3, 4, 5, 6, 7, 8, 4, 8, 1, 2, 3, 4, 5, 6, 7, 8, 2, 1, 2, 3, 4, 5, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 3, 2, 6, 1, 2, 3, 4, 5, 6, 7, 8, 2, 3, 4, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 1, 2, 2, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 3, 4, 7, 4, 5, 2, 4, 5, 6, 8, 1, 2, 4, 5, 6, 8, 2, 6, 2, 4, 5, 6, 7, 8, 4, 8, 7, 1, 4, 7, 8, 2, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 3, 8, 2, 3, 4, 5, 6, 7, 7, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 6, 1, 2, 3, 4, 5, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 7, 4, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 4, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 5, 6, 8, 2, 4, 5, 6, 7, 8, 2, 4, 5, 6, 7, 8, 7, 7, 2, 7, 6, 1, 2, 7, 3, 7, 2, 3, 4, 5, 1, 2, 5, 2, 4, 2, 3, 4, 5, 6, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 7, 3, 7, 4, 1, 7, 8, 8, 1, 3, 4, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 6, 2, 3, 4, 5, 6, 1, 3, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 2, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 3, 4, 6, 7, 8, 2, 3, 4, 5, 6, 7, 8, 1, 4, 4, 1, 2, 6, 2, 8, 1, 2, 3, 4, 5, 6, 7, 8, 7, 7, 7, 2, 4, 5, 7, 8, 1, 2, 3, 4, 7, 8, 4, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 7, 7, 3, 6, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 2, 6, 2, 2, 3, 6, 8, 1, 2, 3, 4, 5, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 2, 4, 5, 1, 7, 3, 1, 1, 2, 3, 4, 5, 6, 7, 8, 1, 4, 7, 8, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 2, 2, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 1, 2, 1, 2, 5, 6, 2, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 7, 7, 5, 4, 2, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 4, 1, 2, 3, 4, 5, 6, 7, 8, 2, 3, 4, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 3, 4, 4, 1, 2, 3, 4, 8, 8, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 3, 3, 6, 2, 4, 6, 2, 2, 4, 5, 2, 5, 6, 8, 4, 2, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 6, 7, 8, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 3, 2, 3, 4, 5, 7, 8, 3, 6, 1, 7, 1, 5, 6, 7, 5, 6, 2, 5, 6, 2, 5, 6, 2, 5, 6, 2, 4, 5, 6, 2, 5, 6, 6, 2, 6, 3, 2, 6, 2, 5, 6, 8, 2, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 5, 6, 7, 8, 3, 5, 6, 1, 2, 3, 4, 6, 7, 7, 1, 7, 1, 2, 3, 4, 5, 6, 7, 8, 2, 5, 6, 2, 6, 5, 1, 2, 3, 4, 5, 8, 3, 6, 3, 4, 5, 7, 5, 6, 4, 5, 6, 2, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 3, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 2, 6, 8, 2, 2, 4, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 3, 6, 1, 2, 3, 4, 5, 7, 8, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 3, 2, 3, 4, 5, 6, 7, 8, 5, 5, 2, 2, 4, 5, 6, 8, 1, 3, 1, 3, 6, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 2, 3, 4, 5, 8, 2, 4, 5, 6, 2, 4, 5, 8, 1, 2, 3, 5, 6, 7, 4, 8, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 5, 7, 2, 3, 6, 8, 2, 4, 5, 6, 7, 8, 2, 6, 8, 2, 6, 1, 4, 8, 1, 2, 3, 8, 5, 3, 5, 8, 6, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 7, 8, 2, 3, 5, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 6, 1, 2, 3, 4, 5, 6, 7, 8, 7, 2, 1, 2, 3, 4, 5, 6, 7, 8, 3, 1, 2, 3, 4, 5, 2, 2, 2, 3, 5, 6, 8, 7, 8, 8, 3, 2, 1, 1, 2, 3, 4, 5, 6, 7, 8, 8, 7, 8, 1, 3, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 5, 6, 2, 8, 5, 7, 1, 3, 7, 8, 2, 4, 2, 5, 6, 2, 5, 6, 4, 4, 1, 7, 2, 3, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 3, 6, 1, 2, 3, 4, 5, 6, 7, 8, 8, 4, 3, 1, 2, 3, 4, 5, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 3, 3, 1, 3, 4, 5, 6, 7, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 3, 5, 6, 3, 6, 2, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 4, 5, 6, 7, 8, 8, 1, 3, 4, 5, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 7, 8, 7, 1, 2, 3, 4, 5, 7, 8, 7, 8, 2, 5, 6, 7, 2, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 7, 2, 6, 1, 6, 1, 3, 8, 3, 1, 2, 3, 4, 5, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 2, 5, 6, 8, 2, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 6, 2, 4, 5, 4, 6, 8, 2, 4, 7, 8, 7, 1, 2, 3, 4, 5, 6, 8, 4, 5, 1, 3, 4, 6, 5, 2, 6, 6, 2, 3, 4, 5, 7, 8, 8, 1, 3, 4, 5, 6, 7, 8, 2, 6, 6, 2, 5, 6, 1, 3, 4, 5, 7, 8, 1, 2, 3, 4, 6, 7, 8, 1, 2, 8, 7, 1, 2, 3, 4, 5, 6, 7, 8, 3, 5, 6, 7, 8, 1, 2, 3, 5, 6, 2, 6, 7, 1, 8, 3, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 5, 6, 7, 8, 2, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 3, 7, 8, 5, 6, 2, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 2, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 4, 6, 8, 5, 5, 6, 3, 1, 2, 3, 4, 5, 6, 7, 8, 1, 3, 1, 2, 3, 4, 5, 6, 7, 8, 1, 1, 2, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 5, 6, 8, 2, 6, 8, 4, 1, 2, 3, 4, 5, 6, 7, 8, 1, 3, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 3, 4, 8, 7, 1, 2, 3, 4, 5, 6, 7, 8, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 4, 5, 1, 4, 1, 2, 3, 4, 5, 6, 7, 8, 4, 8, 5, 1, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 5, 7, 7, 1, 2, 4, 5, 6, 8, 5, 6, 7, 2, 6, 4, 5, 4, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 8, 2, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 5, 6, 7, 8, 1, 2, 5, 8, 2, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 2, 8, 1, 2, 3, 4, 6, 7, 8, 4, 8, 1, 7, 2, 4, 2, 4, 3, 6, 1, 2, 3, 4, 5, 6, 7, 8, 4, 7, 2, 8, 1, 3, 5, 7, 1, 2, 5, 6, 8, 2, 4, 5, 6, 1, 8, 1, 2, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 2, 4, 5, 6, 7, 8, 8, 1, 8, 1, 2, 3, 4, 5, 6, 8, 1, 6, 8, 2, 3, 5, 6, 1, 2, 4, 7, 8, 7, 7, 5, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 8, 1, 1, 1, 2, 6, 3, 3, 8], \"Freq\": [0.9553871911606898, 0.9553871244503805, 0.9807852868324748, 0.016336039632440975, 0.8943981698761433, 0.008168019816220487, 0.06942816843787414, 0.008168019816220487, 0.5164650907515501, 0.009818727961056085, 0.016691837533795346, 0.10800600757161694, 0.04320240302864677, 0.014728091941584127, 0.2592144181718806, 0.03240180227148508, 0.07598238610478714, 0.015196477220957428, 0.6838414749430842, 0.045589431662872285, 0.015196477220957428, 0.1620957570235459, 0.9852009070558118, 0.023551628709025354, 0.011775814354512677, 0.9538409627155269, 0.0023421158212320516, 0.01639481074862436, 0.042158084782176926, 0.004684231642464103, 0.12881637016776282, 0.04918443224587308, 0.7541612944367205, 0.004684231642464103, 0.025781633918158846, 0.4136780351413669, 0.058594622541270104, 0.12773627713996882, 0.13593952429574666, 0.14765844880400067, 0.05156326783631769, 0.03984434332806367, 0.9674459678150126, 0.9762069580411, 0.9905262215194183, 0.22960340870410376, 0.0023192263505465026, 0.7653446956803458, 0.9840263569539308, 0.009072494253847903, 0.06350745977693532, 0.9253944138924861, 0.987459426074061, 0.03725120534668032, 0.00931280133667008, 0.9405929350036781, 0.016841175723559077, 0.21051469654448846, 0.18404999183603848, 0.1575852871275885, 0.3223882209938452, 0.0012029411231113626, 0.06977058514045903, 0.03729117481645224, 0.9895213546137565, 0.20236875335546664, 0.24974605347213105, 0.0778341359059487, 0.1421319003499933, 0.0981386930988049, 0.09610823737951928, 0.06294412729785417, 0.07106595017499664, 0.9808884123116869, 0.9245427909634467, 0.025873399000842727, 0.01034935960033709, 0.027598292267565574, 0.005174679800168545, 0.0034497865334456967, 0.0034497865334456967, 0.8111311914886086, 0.010994248077405839, 0.02809641175337048, 0.04886332478847039, 0.0048863324788470395, 0.010994248077405839, 0.08062448590097615, 0.0048863324788470395, 0.975383763967425, 0.04489969709684661, 0.012628039808488109, 0.5486181739020946, 0.015434270877041023, 0.2567701427725915, 0.002806231068552913, 0.05752773690533472, 0.06314019904244055, 0.0945608022686291, 0.8983276215519765, 0.005562400133448771, 0.16627682722278805, 0.7957533874233429, 0.035630748690597444, 0.008272099047684736, 0.004136049523842368, 0.9843797866744836, 0.0417366320758486, 0.7335529273937026, 0.012647464265408666, 0.046795617782012064, 0.06197257490050247, 0.0796790248720746, 0.0012647464265408666, 0.02150068925119473, 0.0030602449816601383, 0.14077126915636637, 0.006120489963320277, 0.8476878599198584, 0.0017040440191371951, 0.01704044019137195, 0.015336396172234756, 0.01022426411482317, 0.9559686947359665, 0.0018206412829101033, 0.021847695394921242, 0.0018206412829101033, 0.02730961924365155, 0.9485541083961639, 0.9816707200768079, 0.009349244953112457, 0.9331737388005238, 0.018119878423311142, 0.018119878423311142, 0.009059939211655571, 0.02717981763496671, 0.951070823457709, 0.043828148546438205, 0.8984922333809421, 0.09961111234821975, 0.0820127193335702, 0.16841897720286736, 0.4349603150369705, 0.14352225883374783, 0.14645128452423248, 0.0234322055238772, 0.5938922687651681, 0.0425188460316864, 0.11384078131064423, 0.03771833115714116, 0.019202059498180955, 0.011658393266752722, 0.16458908141297962, 0.015773120302077212, 0.9875217941477308, 0.0066724445550522355, 0.0034258483510622387, 0.017129241755311192, 0.976366780052738, 0.9745903319152719, 0.9242582739053696, 0.04436439714745774, 0.012323443652071595, 0.017252821112900232, 0.976655745443057, 0.01664754111550665, 0.9849031855165852, 0.026878739985049246, 0.9676346394617729, 0.9848042213582231, 0.012957950281029251, 0.9954837931496712, 0.6432688393162078, 0.0017623803816882407, 0.33661465290245396, 0.017623803816882406, 0.0017623803816882407, 0.31336560226255294, 0.17830730395084732, 0.23824890825772793, 0.1001555920064334, 0.03262644285058058, 0.05083655048811392, 0.03262644285058058, 0.053112813942805585, 0.0012313680099115376, 0.2302658178534575, 0.0012313680099115376, 0.7659109021649764, 0.9975635735578354, 0.9863216133828685, 0.9840956044776268, 0.08500365390672318, 0.15951302955335708, 0.1521670347712946, 0.3200754869327231, 0.16685902433541958, 0.004197711304035713, 0.1080910660789196, 0.004197711304035713, 0.9970840376918285, 0.9852015163723097, 0.9860484451784844, 0.9769401031628049, 0.012854475041615854, 0.0189865542335364, 0.9778075430271246, 0.9902212779816736, 0.23755464624115946, 0.3316509671548655, 0.0671014747499379, 0.028537408801697726, 0.019282032974120084, 0.2468100220687371, 0.051675848370641826, 0.01773947033619048, 0.12353352493855355, 0.07412011496313213, 0.004117784164618451, 0.049413409975421416, 0.6959055238205183, 0.012353352493855354, 0.041177841646184515, 0.03830979093515175, 0.035362883940140075, 0.748514376732965, 0.002946906995011673, 0.0442036049251751, 0.058938139900233465, 0.05304432591021011, 0.02062834896508171, 0.9923261097351888, 0.013634141925321178, 0.09543899347724824, 0.8862192251458766, 0.9832151079886258, 0.012367485635077053, 0.9927597252590056, 0.9909878567147347, 0.9834386413762018, 0.014533575980929091, 0.9765859865588334, 0.9897473660920086, 0.1717074290206892, 0.07154476209195383, 0.21781405347994834, 0.11924127015325639, 0.10811208493895245, 0.006359534408173674, 0.05246615886743281, 0.25279149272490353, 0.0406012916129453, 0.9541303529042147, 0.1388980728644355, 0.02887979732824897, 0.3933153350418669, 0.29979980083610835, 0.011001827553618655, 0.012377055997820987, 0.10039167642677022, 0.01512751288622565, 0.9846154643104953, 0.9150307481726521, 0.012567459589029231, 0.0017953513698613186, 0.036505477853846814, 0.027528721004540218, 0.006582955022824835, 0.0005984504566204395, 0.03573033041943744, 0.08861121944020485, 0.1200539102093098, 0.45734822936879926, 0.06860223440531989, 0.08718200622342735, 0.07717751370598487, 0.06717302118854239, 0.9903703563053967, 0.08172529344717831, 0.9153232866083971, 0.14369586183957972, 0.4005522148778285, 0.04131256027887917, 0.15626924975054296, 0.07364412919278461, 0.07364412919278461, 0.04131256027887917, 0.06915363351029774, 0.015639895110599194, 0.010426596740399462, 0.21895853154838868, 0.04170638696159785, 0.7090085783471634, 0.16638004796091083, 0.09931870209911514, 0.2835251837701236, 0.03819950080735198, 0.21306832672545215, 0.016977555914378658, 0.08998104634620688, 0.09252767973336368, 0.9919855920246289, 0.9866218875428665, 0.007201619617101216, 0.9751337092415023, 0.9885291069386495, 0.01364656108945598, 0.2028788748632456, 0.02183449774312957, 0.008187936653673589, 0.3166002172753788, 0.333885861322023, 0.014556331828753048, 0.08733799097251828, 0.23138263941737044, 0.0007054348762724708, 0.005643479010179767, 0.7611642314979961, 0.07332768502699498, 0.9218337546250798, 0.018154443129976508, 0.009077221564988254, 0.009077221564988254, 0.962185485888755, 0.0018154443129976508, 0.007945080828345384, 0.3677437411977006, 0.0011350115469064832, 0.00340503464071945, 0.6185812930640334, 0.0011350115469064832, 0.3542765985904491, 0.6446105915816464, 0.1047096602839945, 0.008606273447999548, 0.0014343789079999249, 0.8634961026159548, 0.0014343789079999249, 0.020081304711998947, 0.03431978148656203, 0.9609538816237367, 0.9934708410292353, 0.09423407656014807, 0.013857952435315892, 0.8453350985542694, 0.044345447793010855, 0.9774541689455046, 0.015376644266514977, 0.003844161066628744, 0.05381825493280242, 0.85724791785821, 0.02690912746640121, 0.042285771732916186, 0.05696209340922495, 0.5288237590829398, 0.030790320761743217, 0.02078346651417667, 0.17165603824671843, 0.11315442879940632, 0.047724997180701986, 0.029250804723656057, 0.005932936667804507, 0.023731746671218027, 0.9611357401843301, 0.014702682383396127, 0.011435419631530322, 0.24667833776586834, 0.3904378988479638, 0.001633631375932903, 0.3332608006903122, 0.9986478506508828, 0.9858928360284135, 0.9611474057881982, 0.011442231021288074, 0.02288446204257615, 0.5679038312866959, 0.10255162881838119, 0.004837340981999113, 0.016446959338796984, 0.0019349363927996452, 0.004837340981999113, 0.2776633723667491, 0.023219236713595742, 0.9099735321167008, 0.0273944911501101, 0.03692300981101797, 0.004764259330453931, 0.010719583493521345, 0.0023821296652269653, 0.003573194497840448, 0.004764259330453931, 0.9827428796340875, 0.28338921495745495, 0.04514164486047955, 0.037618037383732955, 0.015047214953493182, 0.022570822430239775, 0.5918571215040652, 0.005015738317831061, 0.24636653132374847, 0.06577206039864779, 0.04124688533474522, 0.14603626969869254, 0.03678776259585385, 0.007803464793059906, 0.36787762595853846, 0.08806767409310466, 0.031136803830630694, 0.015568401915315347, 0.020757869220420465, 0.12454721532252278, 0.8043674322912929, 0.005189467305105116, 0.9838334019381121, 0.1319013418805501, 0.22365879710180236, 0.0709686567726873, 0.12831706628596995, 0.16344296711285558, 0.11326310878873326, 0.08745632450775606, 0.0795709181996797, 0.253076029911134, 0.13067324420248094, 0.027292513029632096, 0.26878990104940703, 0.19352872875557306, 0.007443412644445117, 0.07774230984198234, 0.04135229246913954, 0.9966162004235048, 0.9718938299334281, 0.19703472732254954, 0.008566727274893458, 0.008566727274893458, 0.6296544547046692, 0.017133454549786917, 0.05140036364936075, 0.012850090912340188, 0.08138390911148785, 0.2656578162965824, 0.023854987585815564, 0.15831037216041238, 0.2634891810615083, 0.041204069466408706, 0.0021686352350741424, 0.08023950369774327, 0.16590059548317188, 0.9755584804377252, 0.0011489692255600595, 0.2803484910366545, 0.025277322962321307, 0.18843095299184975, 0.3780108752092596, 0.04710773824796244, 0.045958769022402375, 0.03332010754124173, 0.11277329588568456, 0.24706254953903262, 0.11351522546387985, 0.18103081707965152, 0.06380594372479521, 0.13354732407515277, 0.0979347043217787, 0.04970928173908464, 0.929395344149858, 0.05667044781401573, 0.9957095245037493, 0.15880811425372732, 0.5943511602763261, 0.08019023591029796, 0.01729593323555446, 0.05503251484040056, 0.09591381157898382, 0.050778852365977366, 0.5513132542591829, 0.07737729884339407, 0.03627060883284097, 0.2345499371190383, 0.050778852365977366, 0.995235245633544, 0.9806552303018469, 0.006029517256576397, 0.9888408300785292, 0.9929036098397686, 0.014043932460869326, 0.9830752722608528, 0.9892865180182312, 0.9874545579132223, 0.006171590986957639, 0.05966961015619046, 0.005966961015619047, 0.9189119964053332, 0.011933922031238093, 0.990114840559526, 0.9779364067713909, 0.012073288972486306, 0.9873637522742352, 0.9905265721230397, 0.06208541426264313, 0.05079715712398074, 0.7450249711517175, 0.022576514277324773, 0.11852669995595506, 0.9821470161788408, 0.5429966512529837, 0.02843953228243398, 0.10516013099783728, 0.043651375131177735, 0.006613844716845111, 0.0006613844716845111, 0.25793994395695935, 0.015211842848743756, 0.23320098607665452, 0.12668486000380422, 0.2060992498569352, 0.11155830955558878, 0.07059056875833866, 0.09706203204271566, 0.09454094030134642, 0.0598759288575194, 0.9875910351347225, 0.9887873638991299, 0.9939317261641506, 0.9843329962612672, 0.9941034884964552, 0.02647598926156674, 0.9690212069733427, 0.9645500132824396, 0.36159236780103043, 0.0027922190563786134, 0.048863833486625735, 0.0013961095281893067, 0.5765932351421836, 0.00837665716913584, 0.24272803954923938, 0.2592605995185374, 0.06838467987300552, 0.11497643978648181, 0.06763319987440106, 0.1254971597669442, 0.06763319987440106, 0.0533550799009164, 0.9825526178743421, 0.9078768978769364, 0.04494440088499685, 0.005992586784666246, 0.00898888017699937, 0.02996293392333123, 0.9138978695783305, 0.0009933672495416636, 0.07052907471745812, 0.012913774244041628, 0.8962496440701783, 0.013437026147978684, 0.03359256536994671, 0.010749620918382947, 0.029561457525553104, 0.006718513073989342, 0.002687405229595737, 0.00806221568878721, 0.017226116364983324, 0.9646625164390662, 0.08168497770382785, 0.003141729911685687, 0.6566215515423085, 0.20421244425956964, 0.006283459823371374, 0.01413778460258559, 0.003141729911685687, 0.029846434161014023, 0.11504082845511444, 0.8819796848225441, 0.9856034746219475, 0.7403726207082485, 0.013370160193376947, 0.011698890169204829, 0.0831456837025629, 0.013370160193376947, 0.009609802638989681, 0.005013810072516355, 0.12325616428269373, 0.7821778990454579, 0.009528191461240352, 0.11693689520613158, 0.0008661992237491229, 0.004330996118745614, 0.08488752392741404, 0.21016976190632128, 0.001668013983383502, 0.06338453136857308, 0.033360279667670044, 0.03169226568428654, 0.2168418178398553, 0.44202370559662807, 0.05605729969638595, 0.9389597699144646, 0.9872125308614613, 0.989315024066336, 0.9794569454539563, 0.016324282424232606, 0.022953900251319912, 0.9640638105554363, 0.7834149908308465, 0.013460738674069527, 0.05922725016590592, 0.017050268987154737, 0.017947651565426038, 0.016152886408883432, 0.06461154563553373, 0.02781885992641036, 0.9958261616118773, 0.9823117000589192, 0.9980391748771541, 0.006339700015080785, 0.03486835008294432, 0.06339700015080785, 0.8812183020962291, 0.01267940003016157, 0.040631616159170436, 0.014340570409118977, 0.004780190136372993, 0.2700807427050741, 0.03346133095461095, 0.6333751930694215, 0.9741371287885408, 0.11061215243563592, 0.20082773775548082, 0.12237940269474613, 0.22985362172795265, 0.08786213526802286, 0.08001730176194939, 0.08001730176194939, 0.08786213526802286, 0.8860609772368406, 0.032337991869957686, 0.05659148577242595, 0.01940279512197461, 0.0032337991869957686, 0.9955859399844754, 0.9880192515659036, 0.007108052169538875, 0.08636483204570954, 0.004545517476089975, 0.09091034952179951, 0.8136476282201056, 0.9879480390385231, 0.8786188111369869, 0.005750123109535255, 0.006900147731442306, 0.07590162504586537, 0.010350221597163459, 0.003450073865721153, 0.018400393950512815, 0.19704024346883595, 0.3789235451323768, 0.06241093684533265, 0.059736182409104104, 0.033880222858894866, 0.11233968632159877, 0.11323127113367495, 0.041904486167580496, 0.13239768227632587, 0.5892629239340701, 0.029836097414383294, 0.013053292618792692, 0.02890371937018382, 0.05780743874036764, 0.0717931094033598, 0.07738737766855668, 0.03753919031535628, 0.8446317820955164, 0.005362741473622326, 0.010725482947244652, 0.010725482947244652, 0.08312249284114605, 0.00804411221043349, 0.04575629390290092, 0.38712232867849067, 0.04756246339906806, 0.10234960478280468, 0.1390750512048699, 0.14991206818187275, 0.08488996631985565, 0.04455218090545616, 0.40846508103610407, 0.5892326062605927, 0.9851655152373469, 0.06405479089501825, 0.0058231628086380235, 0.8763860027000225, 0.0494968838734232, 0.879648014693787, 0.011852099566400499, 0.009629830897700404, 0.0018518905572500778, 0.030000627027451262, 0.06518654761520273, 0.0014815124458000624, 0.0014281045535445244, 0.025705881963801438, 0.03998692749924668, 0.19850653294268888, 0.5826666578461659, 0.06426470490950359, 0.04569934571342478, 0.04284313660633573, 0.008311858853879204, 0.9614050074320278, 0.027706196179597346, 0.9650401667473018, 0.03113032795959038, 0.9906203625940093, 0.9978597587070062, 0.02427390711077888, 0.2621581967964119, 0.060684767776947195, 0.14321605195359538, 0.32405665992889804, 0.02184651639970099, 0.06189846313248614, 0.10073671450973234, 0.11996976807173032, 0.04234227108414011, 0.021171135542070056, 0.8115601957793521, 0.9236804098603464, 0.006997578862578382, 0.020992736587735147, 0.005248184146933787, 0.008746973578222978, 0.03148910488160272, 0.03163192442544367, 0.023723943319082754, 0.9342714821372112, 0.0011297115866229883, 0.00677826951973793, 0.0016945673799344824, 0.043484626493107435, 0.07338030720711879, 0.2799322830493791, 0.5816068793453119, 0.0027177891558192147, 0.013588945779096072, 0.0027177891558192147, 0.0027177891558192147, 0.9797264628780593, 0.16023695964940476, 0.03605331592111607, 0.05608293587729166, 0.7451018623697321, 0.014174597634969322, 0.017718247043711655, 0.07087298817484662, 0.021261896452453983, 0.7689719216970857, 0.08859123521855827, 0.010630948226226991, 0.9899391549463227, 0.9898380794321843, 0.010041057252509639, 0.09639414962409254, 0.6486522985121227, 0.01807390305451735, 0.0502052862625482, 0.01807390305451735, 0.040164229010038556, 0.11848447557961375, 0.05149688725413364, 0.016262174922357993, 0.021682899896477325, 0.9106817956520477, 0.0027103624870596656, 0.000534068238375642, 0.18478761047797213, 0.0032044094302538517, 0.25742089089705944, 0.22537679659452092, 0.003738477668629494, 0.3006804182054864, 0.023499002488528247, 0.9943373033357904, 0.001965093484853341, 0.02969872052588991, 0.9622385450388331, 0.00825123820057607, 0.9268890911980453, 0.013752063667626784, 0.049507429203456424, 0.9848680721457798, 0.00834633959445576, 0.0016348891666774393, 0.1209817983341305, 0.05722112083371037, 0.16512380583442135, 0.03269778333354879, 0.027793115833516468, 0.5574972058370068, 0.0376024508335811, 0.19763051635913487, 0.25622716541440393, 0.07670834058144317, 0.06285822353201594, 0.16620140459312688, 0.09588542572680397, 0.0990816065843641, 0.04581192562502857, 0.9903751409671102, 0.973724543479031, 0.9906674074510682, 0.9887430780454226, 0.025227051985281333, 0.8913558368132738, 0.07988566462005756, 0.11834147541845785, 0.10696248739745229, 0.0857217097582419, 0.19040839955149308, 0.2108905779893031, 0.16537462590528085, 0.06523953132043189, 0.057653539306428185, 0.9772269961042364, 0.20435837174517035, 0.09895247473976669, 0.11544455386306114, 0.14627757135443772, 0.1097081785158283, 0.1864321987850677, 0.03656939283860943, 0.10182066241338313, 0.015223789416525055, 0.011417842062393792, 0.022835684124787585, 0.9476808911786847, 0.003805947354131264, 0.010626689593799131, 0.08197731972359329, 0.0561696449957954, 0.1563641468801872, 0.0500972509421959, 0.5859860261723521, 0.007590492566999379, 0.04857915242879603, 0.027846356884344062, 0.9690532195751733, 0.986728575026373, 0.0031676662232610884, 0.01900599733956653, 0.9534675332015876, 0.0031676662232610884, 0.01900599733956653, 0.9741741296410596, 0.009096840796226458, 0.9824588059924575, 0.2595554222817393, 0.08471129970030655, 0.20127404808792837, 0.1978855960999161, 0.05353754141059374, 0.029140687096905454, 0.08200053810989674, 0.09148820367633108, 0.004932655031541744, 0.5606784552519116, 0.15948917935318307, 0.03452858522079221, 0.05261498700311194, 0.06083607872234818, 0.023019056813861474, 0.10358575566237664, 0.9892925355462195, 0.9950476678308668, 0.0028758603116499043, 0.03149599347448769, 0.007873998368621923, 0.9566908017875637, 0.987477403826642, 0.013290081208996253, 0.9236606440252395, 0.059805365440483135, 0.011051152458068397, 0.025786022402159593, 0.05893947977636479, 0.9061945015616086, 0.9914524394712335, 0.9665664595192985, 0.013489610970628261, 0.026979221941256522, 0.001348961097062826, 0.19290143687998412, 0.3048652079361987, 0.09172935460027216, 0.33993819645983214, 0.028328183038319348, 0.22404139869261816, 0.2605773806332605, 0.07582939648057845, 0.07789747093004877, 0.055838010135698675, 0.13511419736539435, 0.10960794582192704, 0.061352875334286204, 0.022263437181958192, 0.6871306293886188, 0.021251462764596458, 0.03440713019029903, 0.09006572314519451, 0.11131718590979096, 0.011131718590979096, 0.022263437181958192, 0.047010699692698665, 0.07639238700063533, 0.035258024769524, 0.7815528823911153, 0.005876337461587333, 0.017629012384762, 0.035258024769524, 0.9804471735899136, 0.8487201491096164, 0.007223150205188225, 0.080357546032719, 0.006320256429539697, 0.009028937756485281, 0.03521285725029259, 0.012640512859079394, 0.49970974124469614, 0.12274473603030049, 0.10374241287916611, 0.04673544342576295, 0.06676491917966136, 0.03184173068568465, 0.09655234465981796, 0.031328154384302635, 0.7115933783548908, 0.06201028011378334, 0.08335808146443006, 0.06709308995917541, 0.010165619690784155, 0.019314677412489892, 0.019314677412489892, 0.0264306111960388, 0.40872160890775844, 0.08811400919310117, 0.09660692574183381, 0.0074313019801410625, 0.07165898337993168, 0.02335552050901477, 0.2712425222751488, 0.0323792443420432, 0.9923360400689304, 0.01670304714602428, 0.01670304714602428, 0.8590138532241058, 0.0023861495922891827, 0.004772299184578365, 0.10021828287614568, 0.010654016407649174, 0.980169509503724, 0.9828621117210721, 0.015725793787537152, 0.020503535188155224, 0.9226590834669851, 0.03075530278223284, 0.03075530278223284, 0.9481453855686628, 0.04514978026517442, 0.03973294927411705, 0.06140546705999908, 0.8957974018164572, 0.03592045494195519, 0.2035492446710794, 0.754329553781059, 0.038571294278831214, 0.9083539802664751, 0.052071247276422136, 0.029803461391904824, 0.002838424894467126, 0.9494531271992537, 0.017030549366802757, 0.006660098639917376, 0.9856945987077717, 0.006660098639917376, 0.993689880275945, 0.9922049715778883, 0.9929875516423965, 0.9913773518879602, 0.018331535533197354, 0.9803386393840323, 0.3347117947660485, 0.18361332741451805, 0.4781597068086407, 0.001912638827234563, 0.5235688503735297, 0.24734547607574428, 0.22600094260727904, 0.0025111215845253225, 0.1641660882380675, 0.07108977928166316, 0.22719413997232554, 0.15097417043322278, 0.01319191780484471, 0.24405047938962712, 0.07548708521661139, 0.054233439864361584, 0.994606395969254, 0.9863756091062225, 0.09831210277414186, 0.17897844351189926, 0.12478074582871851, 0.22372305438987408, 0.08570798703386726, 0.11595786481052629, 0.1140672474494851, 0.05860913819227687, 0.03544521445597943, 0.02238645123535543, 0.1193944065885623, 0.001865537602946286, 0.001865537602946286, 0.001865537602946286, 0.8171054700904733, 0.9850226595473263, 0.008565414430846316, 0.9811626115402848, 0.04513426114367587, 0.005014917904852875, 0.03008950742911725, 0.005014917904852875, 0.9026852228735175, 0.015044753714558625, 0.9913973057287645, 0.992617825480843, 0.0029194641925907147, 0.01069814531471638, 0.14709949807735023, 0.014264193752955174, 0.19613266410313362, 0.35482181960475995, 0.17384486136414118, 0.007132096876477587, 0.09539179572288772, 0.024168788078319958, 0.7803065865286157, 0.19335030462655967, 0.9911139340659123, 0.9765337619196758, 0.9867920533136033, 0.022962279941216496, 0.010437399973280224, 0.8892664777234751, 0.027137239930528585, 0.037574639903808806, 0.010437399973280224, 0.9810160226862661, 0.0173120474591694, 0.9858007174884978, 0.001892131895371397, 0.001892131895371397, 0.007568527581485588, 0.9277506109015101, 0.06185004072676734, 0.017389972088360007, 0.9332618354086537, 0.04637325890229335, 0.01891375533150278, 0.945687766575139, 0.028370632997254168, 0.030012595577084644, 0.36229490375195034, 0.0493064070194962, 0.09503988599410138, 0.047162650192561585, 0.33371147939282214, 0.016435469006498733, 0.06574187602599493, 0.11948859338622096, 0.026229203426243627, 0.046629694979988666, 0.18360442398370538, 0.04954405091623796, 0.14717497478058922, 0.07723043231060622, 0.349722712349915, 0.98064608667602, 0.4871074105593245, 0.07548551925223969, 0.09806665749008918, 0.07419516849579115, 0.04387192571925042, 0.03677499655878344, 0.12258332186261146, 0.06193683630953001, 0.36777972823652816, 0.03935386197083472, 0.208217706063871, 0.09301821920379116, 0.034345188629092124, 0.05437988199606252, 0.16385517075129366, 0.038638337207728635, 0.1389542582891034, 0.14826219903574192, 0.14560278739384522, 0.271259987473465, 0.03723176298655403, 0.10039278948160103, 0.057177350300779396, 0.10039278948160103, 0.017539046861835005, 0.2657165599568003, 0.04472456949767926, 0.20871465765583655, 0.06664837807497301, 0.2736091310446261, 0.014031237489468003, 0.10961904288646877, 0.04167517773568802, 0.04167517773568802, 0.9116445129681753, 0.9866346834250836, 0.061573753064190564, 0.0030786876532095282, 0.9236062959628585, 0.0061573753064190564, 0.1061858164487932, 0.1456968179181116, 0.0580317834080614, 0.11235941042837419, 0.025929094714240198, 0.4951222371623962, 0.0037041563877486, 0.054327627020312796, 0.9777638701592206, 0.019400076788873424, 0.735841820408646, 0.01807703894067483, 0.01701368370887043, 0.08081499761713454, 0.02445717033150124, 0.11696907549848419, 0.007443486622630812, 0.9929114273200472, 0.9779936956180503, 0.5388704839447992, 0.01771914550688895, 0.07191888470443163, 0.009380724091882385, 0.031269080306274614, 0.025015264245019694, 0.2647448799264584, 0.041692107075032826, 0.9878505485331072, 0.17446144170966693, 0.013773271713921073, 0.018364362285228097, 0.050501996284377265, 0.08263963028352644, 0.004591090571307024, 0.6473437705542905, 0.9806911291609635, 0.9878628792317367, 0.9916450982538959, 0.1300984633888055, 0.004818461606992797, 0.004818461606992797, 0.8480492428307322, 0.014455384820978391, 0.0058127821981654795, 0.9939857558862969, 0.006917541778364452, 0.9822909325277521, 0.006917541778364452, 0.04078702789686978, 0.9516973175936283, 0.9895882743289953, 0.981649086995362, 0.8689711012245037, 0.03208903623428743, 0.03850684348114492, 0.021820544639315455, 0.0051342457974859895, 0.011552053044343476, 0.0038506843481144917, 0.017969860291200963, 0.3333574134700062, 0.0697915767117008, 0.05008571975780881, 0.034485249669310984, 0.09278174315790812, 0.057475416115518305, 0.3382838777084792, 0.02299016644620732, 0.02866268226472354, 0.9649769695790259, 0.9945197171126172, 0.00911417351583958, 0.07291338812671665, 0.37975722982664917, 0.06683727244949025, 0.46786090714643175, 0.8020640599417888, 0.1492212204542863, 0.02238318306814294, 0.02238318306814294, 0.7486076421717442, 0.12476794036195737, 0.05232203950662729, 0.06842112858558953, 0.015002135500548654, 0.009001281300329192, 0.9001281300329192, 0.012001708400438923, 0.051007260701865426, 0.009001281300329192, 0.9612139798532926, 0.03151521245420631, 0.9884952322624294, 0.9104969124648367, 0.01207956102772586, 0.015099451284657325, 0.004529835385397198, 0.004529835385397198, 0.0015099451284657326, 0.04982818923936917, 0.004529835385397198, 0.4426475760430959, 0.14117663554862858, 0.06029418809889346, 0.12500014605868157, 0.0029411799072630957, 0.0058823598145261915, 0.010294129675420835, 0.21323554327657443, 0.07062805720164694, 0.09337268579200782, 0.1436502858338582, 0.4022208003348029, 0.1556211429866797, 0.03232131431261809, 0.045489257180721755, 0.05746011433354327, 0.9201428129399774, 0.00450314590345829, 0.025517826786263645, 0.007505243172430484, 0.040528313131124614, 0.008172741200525361, 0.9153470144588405, 0.05993343547051932, 0.016345482401050722, 0.7520006390637131, 0.008925823609064843, 0.015620191315863476, 0.12942444233144024, 0.0022314559022662108, 0.09148969199291465, 0.8383708218524869, 0.0028809993878092335, 0.15557396694169862, 0.024667545876021133, 0.9743680621028348, 0.9958310275797824, 0.9851806927627234, 0.011590361091326157, 0.988567977552871, 0.003907383310485656, 0.003907383310485656, 0.001953691655242828, 0.9854473267250147, 0.1102553337564132, 0.8505411461209019, 0.02362614294780283, 0.9873233791202132, 0.95538664940426, 0.2831984606948285, 0.07308347372769768, 0.1663954089335974, 0.06525310154258722, 0.07308347372769768, 0.19510677361233578, 0.08874421809791862, 0.05481260529577326, 0.06636527298482152, 0.004147829561551345, 0.7528310654215692, 0.06221744342327018, 0.00829565912310269, 0.1057696538195593, 0.032556955765373416, 0.04650993680767631, 0.15813378514609946, 0.7395079952420534, 0.018603974723070522, 0.18148670803919428, 0.0771590195855257, 0.24995175358691427, 0.01630120132088571, 0.34123848098387427, 0.04890360396265714, 0.05977107150991428, 0.024995175358691425, 0.9967313751126354, 0.192410689791087, 0.05868526038628153, 0.30497094331887287, 0.16547319322033482, 0.0962053448955435, 0.07215400867165762, 0.055799100039415225, 0.05483704659045979, 0.9866684958944248, 0.9898836552325244, 0.12123506094952055, 0.31680402788268874, 0.06813941381834367, 0.12123506094952055, 0.09380230993174583, 0.1424733198019913, 0.05929013929648085, 0.07698868834020649, 0.992209269234656, 0.023124615863309637, 0.03468692379496446, 0.023124615863309637, 0.7361336049820235, 0.18114282426259215, 0.9634097908341456, 0.9889839456760733, 0.8143925649417475, 0.03808310555482992, 0.041012575212893754, 0.011717878632255358, 0.09374302905804287, 0.016710298126921444, 0.9691972913614438, 0.9901708549654794, 0.9915945338034525, 0.9859224219715055, 0.9943139440761605, 0.14553066368629852, 0.34005908851321015, 0.07020574730595307, 0.14114280447967648, 0.10457731109115925, 0.06874312757041237, 0.025595845371962054, 0.1053086209589296, 0.9841552820118269, 0.09181655134079209, 0.8977618353321892, 0.0026598836638279818, 0.9841569556163533, 0.0026598836638279818, 0.007979650991483945, 0.24820168801291317, 0.14860483231346394, 0.07193106244960223, 0.05454113526398411, 0.09406369704947984, 0.10671091682083847, 0.21500273611309678, 0.060864745149663425, 0.011041912680533592, 0.9716883158869561, 0.011041912680533592, 0.06700832056851545, 0.9269484345311305, 0.017410579072791962, 0.9749924280763499, 0.9364664786175939, 0.0019591348925054267, 0.05289664209764652, 0.007836539570021707, 0.01521950537966413, 0.9740483442985043, 0.012019286381160281, 0.9795718400645629, 0.0060096431905801405, 0.06111279014940166, 0.9166918522410249, 0.010185465024900277, 0.9740588552085814, 0.9762820987911186, 0.029051469781180474, 0.9586985027789556, 0.9094227080198762, 0.04915798421729061, 0.0035112845869493294, 0.035112845869493294, 0.0035112845869493294, 0.0035112845869493294, 0.11685644499080348, 0.03125230505568, 0.14131477068655304, 0.16305550463833043, 0.025817121567735656, 0.46878457583520006, 0.02853471331170783, 0.02445832569574957, 0.977972070022132, 0.014596598060031822, 0.04381390651071817, 0.426970814427979, 0.03350475203760801, 0.1443281626235422, 0.04725029133508822, 0.1451872588296347, 0.08934600543362137, 0.06872769648740105, 0.980206577906952, 0.9663919661677264, 0.9909458719219878, 0.34587753885861516, 0.03588354870002924, 0.00897088717500731, 0.0328932529750268, 0.07774768885006335, 0.4605055416503752, 0.03787707918336419, 0.10818954033708915, 0.03147332082533503, 0.5271781238243617, 0.1455641088171745, 0.02360499061900127, 0.04327581613483566, 0.06294664165067006, 0.059012476547503176, 0.9957948285525592, 0.9847397546822819, 0.006156208700645328, 0.5807356874275427, 0.002052069566881776, 0.002052069566881776, 0.3837370090068921, 0.02667690436946309, 0.9786080460287657, 0.03482379338136062, 0.04827844082415904, 0.7748294027352738, 0.02057769608898582, 0.03165799398305511, 0.032449443832631486, 0.019786246239409444, 0.03640669308051338, 0.001080396126923497, 0.9928840406426938, 0.003241188380770491, 0.001080396126923497, 0.9846678349334358, 0.01102240113731458, 0.015126038260427624, 0.400840013901332, 0.22689057390641434, 0.01323528347787417, 0.2552518956447161, 0.08886547478001229, 0.02272637399353, 0.18705553979290077, 0.005244547844660769, 0.05769002629126846, 0.49298749739811226, 0.005244547844660769, 0.21852282686086538, 0.008740913074434614, 0.9931796832179407, 0.24487416592147887, 0.0484899338458374, 0.29336409976731626, 0.01212248346145935, 0.00727349007687561, 0.3951929608435748, 0.9673149744116019, 0.920512350253457, 0.0019257580549235502, 0.019257580549235504, 0.005777274164770651, 0.0500697094280123, 0.0038515161098471003, 0.22034673374608074, 0.07576391991269252, 0.15531603582101966, 0.2430759097198885, 0.07450118791414764, 0.050509279941795014, 0.07702665191123739, 0.10417538987995222, 0.03192987391738932, 0.03633399445771888, 0.024222662971812588, 0.7850344863137443, 0.0011010301350823904, 0.1134061039134862, 0.0055051506754119515, 0.18770316541581453, 0.0915991447229175, 0.07658289148965233, 0.03904225840648942, 0.46850710087787306, 0.004504875969979549, 0.07958614213630537, 0.05255688631642807, 0.49629831012570036, 0.02491457380149098, 0.006976080664417475, 0.19832000745986822, 0.06378130893181691, 0.012955578376775311, 0.0279043226576699, 0.16941910185013867, 0.9939354070061033, 0.002442101737115733, 0.002442101737115733, 0.9955251824903264, 0.7093018569421066, 0.02944100938776304, 0.0674878522888722, 0.014494035390898729, 0.0860583351334612, 0.0892289053752203, 0.0036235088477246822, 0.022339161035717828, 0.9605839245358666, 0.015900848088817036, 0.03180169617763407, 0.9301996131957966, 0.015900848088817036, 0.05452010284889398, 0.9346303345524681, 0.02822028801173177, 0.07584202403152913, 0.014110144005865886, 0.2363449120982536, 0.10053477604179444, 0.02822028801173177, 0.49914634420750575, 0.019401448008065595, 0.2806242737867257, 0.21288738011406777, 0.056447411393881604, 0.05483462821119928, 0.10241173210032806, 0.03467483842767013, 0.2403046942196674, 0.017740615009505648, 0.14602045762162064, 0.06854021480198519, 0.03501510973579678, 0.1974256187231095, 0.1542154833044667, 0.049170154097076334, 0.3233310133050171, 0.027565086387754914, 0.9905807566385796, 0.9736903303141414, 0.9883314168039977, 0.9953574022452986, 0.9917046918376173, 0.004757436549725679, 0.0951487309945136, 0.8991555078981535, 0.9945561483199662, 0.3358134347500428, 0.026042674531635977, 0.06853335403062098, 0.4482081353602613, 0.08361069191735761, 0.009594669564286938, 0.026042674531635977, 0.08166264222118609, 0.4546809825366039, 0.0643612349709348, 0.11903368188172887, 0.049828052880723714, 0.10519255608152785, 0.08373881109121624, 0.04013926482058299, 0.6412887874094823, 0.0068077365967036335, 0.34447147179320387, 0.0068077365967036335, 0.742000607875938, 0.06221744227531157, 0.18204362739813384, 0.011521748569502142, 0.1491604051389444, 0.07674194757148589, 0.23346846021747822, 0.04323490004027374, 0.3783053753523952, 0.0010808725010068435, 0.044315772541280586, 0.0745802025694722, 0.2694391132478347, 0.20749908721384971, 0.16723807029175947, 0.04800352017633837, 0.1819488264748309, 0.02013050846104512, 0.0627142763594098, 0.04258376789836468, 0.9902671152799318, 0.021879416015712024, 0.9626943046913291, 0.010939708007856012, 0.9543650267156043, 0.009295763247229912, 0.030985877490766374, 0.0049041509136321425, 0.9465011263310035, 0.034329056395424995, 0.009808301827264285, 0.9944901908096072, 0.07542997641152042, 0.03232713274779447, 0.09159354278541766, 0.38792559297353363, 0.048490699121691704, 0.012571662735253404, 0.35380250840641725, 0.007021635277215866, 0.990050574087437, 0.0033078089036136845, 0.8964162128793085, 0.08931084039756948, 0.006615617807227369, 0.9665349826768356, 0.027920666309999564, 0.9679164320799849, 0.9945691642727011, 0.07288625129575285, 0.08590165331285157, 0.601311573189961, 0.05726776887523438, 0.1457725025915057, 0.036443125647876426, 0.9816637256914414, 0.7154450543981218, 0.02076763583158554, 0.19106224965058693, 0.01765249045684771, 0.0010383817915792768, 0.025959544789481922, 0.026997926581061198, 0.017612852382675244, 0.977513307238476, 0.9952720780504819, 0.1031323907195645, 0.012133222437595823, 0.8796586267256972, 0.048549702773357954, 0.901203857730457, 0.003034356423334872, 0.018206138540009232, 0.024274851386678977, 0.003034356423334872, 0.08972559486216279, 0.04750178551526266, 0.04222380934690014, 0.005277976168362518, 0.005277976168362518, 0.7811404729176525, 0.02111190467345007, 0.009397664827889006, 0.009397664827889006, 0.9773571421004565, 0.9826937390529243, 0.2531789628080466, 0.42442537496975735, 0.14614995520697732, 0.029525243476157034, 0.02804898130234918, 0.07381310869039259, 0.038382816519004145, 0.006643179782135333, 0.9759328191841662, 0.0023803239492296738, 0.0047606478984593475, 0.007140971847689021, 0.009521295796918695, 0.9733592270661829, 0.00735999415550989, 0.0018399985388774724, 0.012879989772142306, 0.003679997077754945, 0.07509520786270221, 0.9094864063371713, 0.012515867977117035, 0.997300532068515, 0.0016269176705848531, 0.9966308871833371, 0.0016527875409342242, 0.20851030537118237, 0.172968776046549, 0.22983522296596237, 0.1263698820431408, 0.04817851752894744, 0.0813506115652719, 0.08293023509081117, 0.04896832929171707, 0.002557467626958165, 0.07416656118178679, 0.002557467626958165, 0.03324707915045614, 0.14577565473661538, 0.012787338134790825, 0.7314357413100352, 0.7997560140861066, 0.03808361971838603, 0.15233447887354412, 0.006347269953064338, 0.020904969936227327, 0.02389139421283123, 0.035837091319246846, 0.020904969936227327, 0.8959272829811712, 0.00331398737646336, 0.03645386114109696, 0.00497098106469504, 0.03479686745286528, 0.19221126783487488, 0.00331398737646336, 0.7241062417572441, 0.02330870611129631, 0.9789656566744451, 0.39521861435179223, 0.02721891283414547, 0.06097036474848585, 0.2732778848548205, 0.03701772145443784, 0.013065078160389825, 0.07621295593560731, 0.1164969469301426, 0.03163873061043106, 0.9491619183129316, 0.4860789625994297, 0.07294500120864565, 0.13130100217556218, 0.03713563697894688, 0.11538572918458495, 0.049735228096803856, 0.09947045619360771, 0.008620772870112668, 0.038699134043085025, 0.04837391755385628, 0.8997548665017269, 0.9767676010496141, 0.010733709901644111, 0.004195247037049788, 0.004195247037049788, 0.9900783007437499, 0.23228468159868151, 0.027062293001788137, 0.5592873887036215, 0.065400541420988, 0.015786337584376413, 0.00902076433392938, 0.054124586003576274, 0.03608305733571752, 0.034996396525739645, 0.9519019855001184, 0.9438087648251295, 0.0026326604318692597, 0.00789798129560778, 0.009214311511542408, 0.0052653208637385195, 0.0026326604318692597, 0.028959264750561858, 0.021469084523874755, 0.010734542261937378, 0.9124360922646771, 0.03220362678581214, 0.03220362678581214, 0.9784251561200268, 0.9851503076017529, 0.9940462507024984, 0.9835341831816026, 0.13398130862557225, 0.24939095070898598, 0.16847154648958096, 0.07693976138894248, 0.10148089217679483, 0.11607291588849082, 0.024541130787852344, 0.13000166579510972, 0.03988834844051669, 0.9528883238567877, 0.07835480264386968, 0.14465502026560556, 0.08799847066157672, 0.28810458202899775, 0.1796133168297936, 0.054245632599602085, 0.039780130573041535, 0.1265731427324049, 0.9890700588681522, 0.9952536168099853, 0.01023941574366019, 0.9829839113913782, 0.9876260400366038, 0.821952622381982, 0.006338966239449732, 0.036625138272376234, 0.016903909971865954, 0.037329467854537314, 0.0021129887464832442, 0.061276673648014084, 0.017608239554027034, 0.0034799828657664077, 0.03131984579189767, 0.6437968301667855, 0.24707878346941495, 0.07655962304686097, 0.007331480673186204, 0.03665740336593102, 0.9530924875142065, 0.9734393867633304, 0.1684196217326795, 0.0219677767477408, 0.7267672807377582, 0.03661296124623467, 0.0024408640830823115, 0.003661296124623467, 0.018306480623117335, 0.0219677767477408, 0.005649299477941954, 0.994276708117784, 0.6123435656374717, 0.001229605553488899, 0.031969744390711374, 0.10697568315353422, 0.007377633320933394, 0.001229605553488899, 0.011066449981400092, 0.2274770273954463, 0.003859216840879053, 0.05402903577230674, 0.003859216840879053, 0.019296084204395266, 0.003859216840879053, 0.9030567407656984, 0.01157765052263716, 0.9891026265897761, 0.9770740038691784, 0.016017606620806205, 0.993091283964, 0.2197633780676679, 0.0795899801650473, 0.19600517503332543, 0.34211812369453165, 0.054643866978987696, 0.007127460910302742, 0.0795899801650473, 0.021382382730908228, 0.9862748720718569, 0.9846830622904302, 0.9806141402189825, 0.003903546671725944, 0.5595083562807186, 0.14443122685385992, 0.04554137783680268, 0.04163783116507673, 0.06636029341934105, 0.020818915582538365, 0.11840758237568696, 0.46873946043387943, 0.18282037779070745, 0.04855229705261411, 0.09290871658216279, 0.11208987097331899, 0.029371142661457916, 0.04555524167899595, 0.01978056546587982, 0.016845420520828953, 0.9770343902080793, 0.9906482271315747, 0.971065712941331, 0.07961242766484589, 0.19602682660872428, 0.11716545958222602, 0.07510606383476026, 0.2583648595915753, 0.18250773511846743, 0.039055153194075334, 0.05182318404598458, 0.022482203719742907, 0.966734759948945, 0.9701426044327324, 0.004407600487165611, 0.9828949086379314, 0.0018889716373566906, 0.003777943274713381, 0.003777943274713381, 0.0018889716373566906, 0.25504481716803795, 0.060685905049629604, 0.12465212929113108, 0.06888670302930928, 0.04510438888823822, 0.019681915151231223, 0.36657566969168154, 0.05904574545369367, 0.0177411267478015, 0.9757619711290826, 0.9911829126036847, 0.006149601711874779, 0.06149601711874779, 0.024598406847499116, 0.8670938413743439, 0.006149601711874779, 0.030748008559373895, 0.767324644087176, 0.010163240319035444, 0.21850966685926204, 0.969562387191772, 0.02364786310223834, 0.9810121147847599, 0.9688499892117454, 0.9935402701557648, 0.978223015035064, 0.017205160274276793, 0.12043612191993756, 0.09355305899138007, 0.04946483578854578, 0.37313691344837796, 0.09462838150852236, 0.12366208947136446, 0.12796337953993367, 0.03319612786614008, 0.008852300764304023, 0.8675254749017942, 0.08188378206981221, 0.004426150382152012, 0.020275922029933526, 0.8191472500093144, 0.004055184405986705, 0.028386290841906938, 0.08515887252572081, 0.01622073762394682, 0.028386290841906938, 0.029275888709066066, 0.009758629569688688, 0.7904489951447838, 0.0878276661271982, 0.07318972177266517, 0.15361139687515266, 0.32661063995784884, 0.0499609883040545, 0.0760600120449785, 0.0894823671117394, 0.2333998408831203, 0.03728431962989142, 0.033555887666902276, 0.005876429096251815, 0.5509152277736077, 0.013221965466566584, 0.09402286554002905, 0.31438895664947214, 0.0029382145481259077, 0.0190983945628184, 0.0015105805622967266, 0.32024307920690603, 0.015105805622967266, 0.6616342862859663, 0.33264725016497176, 0.005993644147116608, 0.6593008561828269, 0.1757463959102541, 0.10666688769119467, 0.07314300870253349, 0.26717515678842096, 0.03352387898866118, 0.15441301837201515, 0.04469850531821491, 0.1422225169215929, 0.985917845939298, 0.9652498889654573, 0.003448780966283025, 0.7656293745148316, 0.05862927642681143, 0.017243904831415125, 0.0827707431907926, 0.06207805739309445, 0.010346342898849075, 0.018484220610203397, 0.9611794717305766, 0.9686992446630177, 0.028916395363075154, 0.01118677801123514, 0.9844364649886923, 0.020312152637366018, 0.9749833265935688, 0.985758282344959, 0.992181735820875, 0.7539060311626394, 0.08112054647864439, 0.022533485132956773, 0.040560273239322195, 0.01480771880165731, 0.016739160384482175, 0.06244994451133735, 0.00901339405318271, 0.016050121331041375, 0.9790574011935239, 0.9771566124694082, 0.010979287780555149, 0.9330631365507808, 0.013843666714403275, 0.02907170010024688, 0.02353423341448557, 0.003599136892100154, 0.014396547568400616, 0.6766377357148289, 0.08278014851830354, 0.21954735041810938, 0.13667193239050088, 0.779030014625855, 0.02050078985857513, 0.054668772956200345, 0.9882644154239769, 0.006544797453138919, 0.99477882900239, 0.03417084586029542, 0.014644648225840893, 0.912849739410749, 0.03417084586029542, 0.9871037397991144, 0.004968630248460436, 0.042233357111913714, 0.022358836118071965, 0.603688575187943, 0.18632363431726637, 0.05962356298152524, 0.01490589074538131, 0.0670765083542159, 0.029151620959275787, 0.7579421449411704, 0.19945845919504485, 0.003068591679923767, 0.0015342958399618834, 0.007671479199809417, 0.9665155319784955, 0.9951517844478764, 0.002277235204686216, 0.9248685029668877, 0.005476645465384976, 0.000684580683173122, 0.012322452297116196, 0.01437619434663556, 0.005476645465384976, 0.036967356891348585, 0.9968505937301239, 0.000820453163563888, 0.000820453163563888, 0.9853235210841544, 0.9653238707256442, 0.020322607804750405, 0.010161303902375202, 0.022751973661183256, 0.005687993415295814, 0.007583991220394419, 0.9005989574218372, 0.06067192976315535, 0.9923775303521987, 0.9945603900970367, 0.9586139316966484, 0.11351954541083807, 0.035382715452728745, 0.04717695393697167, 0.11351954541083807, 0.49683229614873287, 0.0014742798105303646, 0.1916563753689474, 0.14057188432555456, 0.31705071736470186, 0.058062300047511665, 0.04278274740342965, 0.055770367150899364, 0.3353861805376003, 0.03361501581698044, 0.01757148554069432, 0.1661584732620173, 0.33791779393736104, 0.07187754180435581, 0.0914805077509983, 0.0840127111998964, 0.10548262628431436, 0.06440974525325391, 0.07841186378656997, 0.9728928275477855, 0.9944339804447953, 0.991867019588097, 0.9962975003379401, 0.9798490006182502, 0.9846361869972095, 0.991158758463664, 0.9834540634547444, 0.9857489946359027], \"Term\": [\"30602-7415\", \"542-0358\", \"80-bit\", \"absolute\", \"absolute\", \"absolute\", \"absolute\", \"absolute\", \"access\", \"access\", \"access\", \"access\", \"access\", \"access\", \"access\", \"access\", \"accident\", \"accident\", \"accident\", \"accident\", \"accident\", \"accident\", \"adaptec\", \"adobe.com\", \"adobe.com\", \"adobe.com\", \"agency\", \"agency\", \"agency\", \"agency\", \"agency\", \"agency\", \"agency\", \"agency\", \"agree\", \"agree\", \"agree\", \"agree\", \"agree\", \"agree\", \"agree\", \"agree\", \"ai.uga.edu\", \"aisun3.ai.uga.edu\", \"ak296\", \"algorithm\", \"algorithm\", \"algorithm\", \"alink\", \"allan\", \"allan\", \"allan\", \"alomar\", \"amanda\", \"amanda\", \"amanda\", \"american\", \"american\", \"american\", \"american\", \"american\", \"american\", \"american\", \"american\", \"animation\", \"anything\", \"anything\", \"anything\", \"anything\", \"anything\", \"anything\", \"anything\", \"anything\", \"apostle\", \"apple\", \"apple\", \"apple\", \"apple\", \"apple\", \"apple\", \"apple\", \"application\", \"application\", \"application\", \"application\", \"application\", \"application\", \"application\", \"application\", \"appressian\", \"april\", \"april\", \"april\", \"april\", \"april\", \"april\", \"april\", \"april\", \"arab\", \"arab\", \"arab\", \"arabs\", \"arabs\", \"arabs\", \"argic\", \"argic\", \"argic\", \"argument\", \"argument\", \"argument\", \"argument\", \"argument\", \"argument\", \"argument\", \"argument\", \"armenia\", \"armenia\", \"armenia\", \"armenia\", \"armenian\", \"armenian\", \"armenian\", \"armenian\", \"armenian\", \"armenians\", \"armenians\", \"armenians\", \"armenians\", \"armenians\", \"arrogance\", \"arrogance\", \"assertion\", \"assertion\", \"assertion\", \"assertion\", \"assertion\", \"atheism\", \"atheism\", \"atheist\", \"atheist\", \"attack\", \"attack\", \"attack\", \"attack\", \"attack\", \"attack\", \"available\", \"available\", \"available\", \"available\", \"available\", \"available\", \"available\", \"available\", \"baalke\", \"baalke\", \"banks\", \"banks\", \"banks\", \"baptism\", \"baseball\", \"baseball\", \"baseball\", \"baseball\", \"batf\", \"batf\", \"batf/fbi\", \"bayonet\", \"bayonet\", \"beauchaine\", \"beauchaine\", \"behanna\", \"belief\", \"belief\", \"belief\", \"belief\", \"belief\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"bible\", \"bible\", \"bible\", \"bible\", \"bike\", \"biker\", \"bikers\", \"bill\", \"bill\", \"bill\", \"bill\", \"bill\", \"bill\", \"bill\", \"bill\", \"bios\", \"bitmap\", \"blah\", \"bobbe\", \"bobbe\", \"bontchev\", \"bontchev\", \"bony1.bony.com\", \"book\", \"book\", \"book\", \"book\", \"book\", \"book\", \"book\", \"book\", \"border\", \"border\", \"border\", \"border\", \"border\", \"border\", \"border\", \"boston\", \"boston\", \"boston\", \"boston\", \"boston\", \"boston\", \"boston\", \"boston\", \"boyle\", \"brake\", \"brake\", \"brake\", \"braves\", \"braves\", \"broward\", \"buphy.bu.edu\", \"cache\", \"cache\", \"cactus.org\", \"cadre.dsl.pitt.edu\", \"california\", \"california\", \"california\", \"california\", \"california\", \"california\", \"california\", \"california\", \"callison\", \"callison\", \"canada\", \"canada\", \"canada\", \"canada\", \"canada\", \"canada\", \"canada\", \"canada\", \"candida\", \"card\", \"card\", \"card\", \"card\", \"card\", \"card\", \"card\", \"carry\", \"carry\", \"carry\", \"carry\", \"carry\", \"carry\", \"carry\", \"carry\", \"catcher\", \"catholic\", \"catholic\", \"cause\", \"cause\", \"cause\", \"cause\", \"cause\", \"cause\", \"cause\", \"cause\", \"cco.caltech.edu\", \"cco.caltech.edu\", \"cco.caltech.edu\", \"cco.caltech.edu\", \"cco.caltech.edu\", \"center\", \"center\", \"center\", \"center\", \"center\", \"center\", \"center\", \"center\", \"centris\", \"char\", \"char\", \"charley\", \"chastity\", \"child\", \"child\", \"child\", \"child\", \"child\", \"child\", \"child\", \"child\", \"chip\", \"chip\", \"chip\", \"chip\", \"chopin.udel.edu\", \"chopin.udel.edu\", \"christ\", \"christ\", \"christ\", \"christ\", \"christ\", \"christian\", \"christian\", \"christian\", \"christian\", \"christian\", \"christian\", \"christians\", \"christians\", \"church\", \"church\", \"church\", \"church\", \"church\", \"church\", \"cigarette\", \"cigarette\", \"cipher\", \"circuit\", \"circuit\", \"circuit\", \"circuit\", \"citizenship\", \"civilian\", \"civilian\", \"civilian\", \"civilian\", \"civilian\", \"civilian\", \"claim\", \"claim\", \"claim\", \"claim\", \"claim\", \"claim\", \"claim\", \"claim\", \"clayton\", \"clayton\", \"clayton\", \"clinton\", \"clinton\", \"clinton\", \"clinton\", \"clinton\", \"clinton\", \"clipper\", \"cnsvax.uwec.edu\", \"coach\", \"coach\", \"coach\", \"code\", \"code\", \"code\", \"code\", \"code\", \"code\", \"code\", \"code\", \"color\", \"color\", \"color\", \"color\", \"color\", \"color\", \"color\", \"color\", \"commandment\", \"communication\", \"communication\", \"communication\", \"communication\", \"communication\", \"communication\", \"communication\", \"company\", \"company\", \"company\", \"company\", \"company\", \"company\", \"company\", \"company\", \"compound\", \"compound\", \"compound\", \"compound\", \"compound\", \"compound\", \"concealed\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"controller\", \"cookamunga\", \"cool\", \"cool\", \"cool\", \"cool\", \"cool\", \"cool\", \"cool\", \"cool\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"countersteering\", \"country\", \"country\", \"country\", \"country\", \"country\", \"country\", \"country\", \"country\", \"course\", \"course\", \"course\", \"course\", \"course\", \"course\", \"course\", \"course\", \"covington\", \"covington\", \"cramer\", \"crime\", \"crime\", \"crime\", \"crime\", \"crime\", \"crime\", \"criminal\", \"criminal\", \"criminal\", \"criminal\", \"criminal\", \"criminal\", \"crypto\", \"cryptographic\", \"cryptography\", \"cryptography\", \"cs.pitt.edu\", \"cs.rochester.edu\", \"cs.rochester.edu\", \"csrc.ncsl.nist.gov\", \"cubs\", \"cubs\", \"cunixb.cc.columbia.edu\", \"cunixb.cc.columbia.edu\", \"cunixb.cc.columbia.edu\", \"cunixb.cc.columbia.edu\", \"cursor\", \"cyprus\", \"cyprus\", \"d012s658.uucp\", \"daker\", \"dare\", \"dare\", \"dare\", \"dare\", \"dare\", \"darice\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"david\", \"david\", \"david\", \"david\", \"david\", \"david\", \"david\", \"david\", \"decrypt\", \"defenseman\", \"denning\", \"desire.wright.edu\", \"desktop\", \"detector\", \"detector\", \"detectors\", \"device\", \"device\", \"device\", \"device\", \"device\", \"device\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"disciple\", \"disease\", \"disease\", \"disease\", \"disease\", \"disease\", \"disk\", \"disk\", \"disk\", \"disk\", \"display\", \"display\", \"display\", \"display\", \"display\", \"display\", \"display\", \"display\", \"dividian\", \"dividian\", \"division\", \"division\", \"division\", \"division\", \"division\", \"division\", \"division\", \"division\", \"doctrine\", \"doctrine\", \"dorothy\", \"drive\", \"drive\", \"drive\", \"drive\", \"drive\", \"drive\", \"drive\", \"drive\", \"driver\", \"driver\", \"driver\", \"driver\", \"driver\", \"driver\", \"drug\", \"drug\", \"drug\", \"drug\", \"drug\", \"drug\", \"drug\", \"east.sun.com\", \"east.sun.com\", \"egreen\", \"eisa\", \"elias\", \"elias\", \"eliot\", \"eliot\", \"email\", \"email\", \"email\", \"email\", \"email\", \"email\", \"email\", \"email\", \"encrypt\", \"encrypted\", \"encryption\", \"enforcement\", \"enforcement\", \"enforcement\", \"enforcement\", \"enforcement\", \"engine\", \"engine\", \"engine\", \"engine\", \"engine\", \"engine\", \"engr.latech.edu\", \"enough\", \"enough\", \"enough\", \"enough\", \"enough\", \"enough\", \"enough\", \"enough\", \"entry\", \"entry\", \"entry\", \"entry\", \"entry\", \"escrow\", \"espn\", \"espn\", \"eternal\", \"eternal\", \"eternal\", \"eternal\", \"ethernet\", \"evidence\", \"evidence\", \"evidence\", \"evidence\", \"evidence\", \"evidence\", \"evidence\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"exist\", \"exist\", \"exist\", \"exist\", \"exist\", \"exist\", \"exist\", \"exist\", \"existence\", \"existence\", \"existence\", \"existence\", \"existence\", \"existence\", \"existence\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"faith\", \"faith\", \"fallacy\", \"father\", \"father\", \"father\", \"father\", \"file\", \"file\", \"file\", \"file\", \"file\", \"file\", \"file\", \"fire\", \"fire\", \"fire\", \"fire\", \"fire\", \"fire\", \"fire\", \"fire\", \"firearm\", \"firearm\", \"firearm\", \"floppy\", \"floppy\", \"flyers\", \"font\", \"force\", \"force\", \"force\", \"force\", \"force\", \"force\", \"force\", \"force\", \"ford\", \"ford\", \"ford\", \"ford\", \"format\", \"format\", \"format\", \"format\", \"format\", \"format\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"gary\", \"gary\", \"gary\", \"gary\", \"gary\", \"gary\", \"gary\", \"gary\", \"genetic\", \"genocide\", \"genocide\", \"genocide\", \"genocide\", \"georgia\", \"georgia\", \"georgia\", \"georgia\", \"georgia\", \"georgia\", \"georgia\", \"glutamate\", \"gnv.ifas.ufl.edu\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"gordon\", \"gordon\", \"gordon\", \"gordon\", \"gordon\", \"government\", \"government\", \"government\", \"government\", \"government\", \"government\", \"government\", \"government\", \"graphic\", \"graphic\", \"greece\", \"greece\", \"greek\", \"greek\", \"greek\", \"greek\", \"greeks\", \"greeks\", \"ground\", \"ground\", \"ground\", \"ground\", \"ground\", \"ground\", \"ground\", \"ground\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"gtoal\", \"gtoal.com\", \"guday\", \"guns\", \"handgun\", \"handgun\", \"handgun\", \"happen\", \"happen\", \"happen\", \"happen\", \"happen\", \"happen\", \"happen\", \"happen\", \"harley\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"heaven\", \"heaven\", \"heaven\", \"heaven\", \"heaven\", \"hell\", \"hell\", \"hell\", \"hell\", \"hell\", \"hell\", \"hell\", \"hell\", \"helmet\", \"helmet\", \"hendricks\", \"henry\", \"henry\", \"henry\", \"henry\", \"henry\", \"heterosexual\", \"higgins\", \"higgins\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"history\", \"history\", \"history\", \"history\", \"history\", \"history\", \"history\", \"history\", \"hitter\", \"hockey\", \"hockey\", \"holy\", \"holy\", \"holy\", \"homeopathy\", \"homicide\", \"homicide\", \"homicide\", \"homosexual\", \"homosexual\", \"homosexual\", \"homosexual\", \"horne\", \"horus.ap.mchp.sni.de\", \"house\", \"house\", \"house\", \"house\", \"house\", \"house\", \"house\", \"house\", \"however\", \"however\", \"however\", \"however\", \"however\", \"however\", \"however\", \"however\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"iastate.edu\", \"iastate.edu\", \"iastate.edu\", \"iastate.edu\", \"iastate.edu\", \"iastate.edu\", \"iastate.edu\", \"ifi.uio.no\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"include\", \"include\", \"include\", \"include\", \"include\", \"include\", \"include\", \"include\", \"info\", \"info\", \"info\", \"info\", \"info\", \"info\", \"info\", \"info\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"inning\", \"insurance\", \"insurance\", \"insurance\", \"insurance\", \"insurance\", \"insurance\", \"intellect\", \"intellect\", \"interface\", \"interface\", \"intergraph\", \"intergraph\", \"intergraph\", \"intergraph\", \"iran\", \"iran\", \"islam\", \"islam\", \"islam\", \"islamic\", \"islamic\", \"islamic\", \"israel\", \"israel\", \"israel\", \"israeli\", \"israeli\", \"israeli\", \"israeli\", \"israelis\", \"israelis\", \"israelis\", \"jaeger\", \"jake\", \"jayne\", \"jays\", \"jesus\", \"jesus\", \"jewish\", \"jewish\", \"jewish\", \"jewish\", \"jews\", \"jews\", \"jews\", \"jews\", \"john\", \"john\", \"john\", \"john\", \"john\", \"john\", \"john\", \"john\", \"jpeg\", \"kaldis\", \"keep\", \"keep\", \"keep\", \"keep\", \"keep\", \"keep\", \"keep\", \"keep\", \"keith\", \"keith\", \"keith\", \"keith\", \"keith\", \"keith\", \"keith\", \"kelvin.jpl.nasa.gov\", \"kelvin.jpl.nasa.gov\", \"kendig\", \"kent\", \"kent\", \"kent\", \"kent\", \"kent\", \"kent\", \"key-escrow\", \"keyboard\", \"keyboard\", \"kill\", \"kill\", \"kill\", \"kill\", \"kill\", \"kill\", \"kill\", \"kill\", \"koresh\", \"koresh\", \"koresh\", \"kratz\", \"ksand\", \"laughter\", \"launch\", \"launch\", \"launch\", \"launch\", \"launch\", \"launch\", \"leafs\", \"leafs\", \"league\", \"league\", \"league\", \"league\", \"lebanese\", \"lebanese\", \"lebanon\", \"lebanon\", \"lebanon\", \"libertarian\", \"libertarian\", \"libertarian\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"light\", \"light\", \"light\", \"light\", \"light\", \"light\", \"light\", \"light\", \"lindros\", \"line\", \"line\", \"line\", \"line\", \"line\", \"line\", \"line\", \"line\", \"list\", \"list\", \"list\", \"list\", \"list\", \"list\", \"list\", \"list\", \"little\", \"little\", \"little\", \"little\", \"little\", \"little\", \"little\", \"little\", \"live\", \"live\", \"live\", \"live\", \"live\", \"live\", \"live\", \"live\", \"livesey\", \"livesey\", \"livesey\", \"livni\", \"lord\", \"lord\", \"lord\", \"lord\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"lunar\", \"lunar\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"magpie.linknet.com\", \"mahan\", \"mail\", \"mail\", \"mail\", \"mail\", \"mail\", \"mail\", \"mail\", \"mail\", \"mail.sas.upenn.edu\", \"male\", \"male\", \"male\", \"male\", \"male\", \"male\", \"male\", \"mane\", \"manes\", \"mangoe\", \"marriage\", \"marriage\", \"marriage\", \"marriage\", \"marriage\", \"mars\", \"mars\", \"maynard\", \"maynard\", \"maynard\", \"mccall\", \"mccall\", \"mcovingt\", \"melkonian\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"message\", \"message\", \"message\", \"message\", \"message\", \"message\", \"message\", \"message\", \"methodology\", \"methodology\", \"mets\", \"mile\", \"mile\", \"mile\", \"mile\", \"mile\", \"militia\", \"militia\", \"militia\", \"militia\", \"minority\", \"minority\", \"minority\", \"minority\", \"mission\", \"mission\", \"mission\", \"mission\", \"mission\", \"mission\", \"mksol.dseg.ti.com\", \"mksol.dseg.ti.com\", \"mlee\", \"mode\", \"mode\", \"mode\", \"mode\", \"mode\", \"mode\", \"mode\", \"mode\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"money\", \"money\", \"money\", \"money\", \"money\", \"money\", \"money\", \"money\", \"monitor\", \"monitor\", \"monitor\", \"monitor\", \"monitor\", \"moon\", \"moon\", \"moon\", \"moon\", \"moral\", \"moral\", \"moral\", \"moral\", \"moral\", \"moral\", \"morality\", \"morality\", \"morality\", \"mormon\", \"mormon\", \"motherboard\", \"motorcycle\", \"motorcycle\", \"mouse\", \"mouse\", \"mouse\", \"mouse\", \"murders\", \"myers\", \"myers\", \"myers\", \"n3jxp\", \"n4tmi\", \"name\", \"name\", \"name\", \"name\", \"name\", \"name\", \"name\", \"name\", \"nasa\", \"nasa\", \"nasa\", \"nasa\", \"nasa\", \"nasa\", \"neutral\", \"neutral\", \"neutral\", \"neutral\", \"neutral\", \"news\", \"news\", \"news\", \"news\", \"news\", \"news\", \"news\", \"news\", \"newton.apple.com\", \"next\", \"next\", \"next\", \"next\", \"next\", \"next\", \"next\", \"next\", \"nist\", \"noring\", \"nothing\", \"nothing\", \"nothing\", \"nothing\", \"nothing\", \"nothing\", \"nothing\", \"nothing\", \"nsmca\", \"nuclear\", \"nuclear\", \"nuclear\", \"nuclear\", \"nuclear\", \"nyeda\", \"o'dwyer\", \"objective\", \"objective\", \"objective\", \"objective\", \"objective\", \"odometer\", \"odometer\", \"ohanus\", \"oilers\", \"okcforum.osrhe.edu\", \"openwindows\", \"opinion\", \"opinion\", \"opinion\", \"opinion\", \"opinion\", \"opinion\", \"opinion\", \"opinion\", \"optilink\", \"optilink.com\", \"optilink.com\", \"orbit\", \"orbit\", \"orbit\", \"orbit\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"orion.oac.uci.edu\", \"orion.oac.uci.edu\", \"orion.oac.uci.edu\", \"ottoman\", \"ottoman\", \"outlet\", \"outlet\", \"output\", \"output\", \"output\", \"output\", \"pa146008\", \"pa146008\", \"palestinian\", \"palestinian\", \"palestinian\", \"palestinians\", \"palestinians\", \"palestinians\", \"parr\", \"parsli\", \"patent\", \"patent\", \"patient\", \"patient\", \"patient\", \"patient\", \"patient\", \"patient\", \"paul\", \"paul\", \"paul\", \"paul\", \"paul\", \"paul\", \"paul\", \"paul\", \"pens\", \"pens\", \"person\", \"person\", \"person\", \"person\", \"person\", \"person\", \"person\", \"person\", \"petaluma\", \"phds\", \"phillies\", \"phone\", \"phone\", \"phone\", \"phone\", \"phone\", \"phone\", \"phone\", \"pick\", \"pick\", \"pick\", \"pick\", \"pick\", \"pick\", \"pick\", \"pick\", \"pitcher\", \"pitching\", \"pittsburgh\", \"pittsburgh\", \"pittsburgh\", \"pittsburgh\", \"pittsburgh\", \"pittsburgh\", \"plaintext\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"player\", \"player\", \"player\", \"player\", \"playoff\", \"playoff\", \"police\", \"police\", \"police\", \"police\", \"police\", \"police\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"polygon\", \"population\", \"population\", \"population\", \"population\", \"population\", \"population\", \"porsche\", \"port\", \"port\", \"port\", \"port\", \"port\", \"port\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"president\", \"president\", \"president\", \"president\", \"president\", \"president\", \"president\", \"press\", \"press\", \"press\", \"press\", \"press\", \"press\", \"press\", \"press\", \"price\", \"price\", \"price\", \"price\", \"price\", \"price\", \"price\", \"price\", \"printer\", \"printer\", \"printer\", \"privacy\", \"program\", \"program\", \"program\", \"program\", \"program\", \"program\", \"program\", \"promiscuous\", \"promiscuous\", \"prophecy\", \"prophecy\", \"prophecy\", \"prophecy\", \"prophet\", \"prophet\", \"protect\", \"protect\", \"protect\", \"protect\", \"protect\", \"protect\", \"protect\", \"protect\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"public\", \"public\", \"public\", \"public\", \"public\", \"public\", \"public\", \"public\", \"public-key\", \"quack\", \"quack.kfu.com\", \"quadra\", \"qur'an\", \"radar\", \"radar\", \"radar\", \"rangers\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"reason\", \"reason\", \"reason\", \"reason\", \"reason\", \"reason\", \"reason\", \"reason\", \"religion\", \"religion\", \"religion\", \"religion\", \"religious\", \"religious\", \"religious\", \"religious\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"research\", \"research\", \"research\", \"research\", \"research\", \"research\", \"research\", \"research\", \"resurrection\", \"revolver\", \"revolver\", \"revolver\", \"ride\", \"ride\", \"ride\", \"rider\", \"rider\", \"rider\", \"rider\", \"ripem\", \"road\", \"road\", \"road\", \"road\", \"road\", \"road\", \"road\", \"roby\", \"roby\", \"roger\", \"roger\", \"roger\", \"roger\", \"romulus.rutgers.edu\", \"rushdie\", \"rushdie\", \"sabbath\", \"safety\", \"safety\", \"safety\", \"safety\", \"safety\", \"safety\", \"sahak\", \"sale\", \"sale\", \"sale\", \"sale\", \"sale\", \"sale\", \"sale\", \"salvation\", \"salvation\", \"sandvik\", \"satan\", \"satan\", \"satan\", \"satellite\", \"satellite\", \"satellite\", \"satellite\", \"satellite\", \"satellite\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"schneider\", \"schneider\", \"schneider\", \"sci.crypt\", \"science\", \"science\", \"science\", \"science\", \"science\", \"science\", \"science\", \"science\", \"score\", \"score\", \"score\", \"score\", \"score\", \"screen\", \"screen\", \"screen\", \"screen\", \"screen\", \"scripture\", \"scripture\", \"scripture\", \"scsi\", \"scsi\", \"season\", \"season\", \"second\", \"second\", \"second\", \"second\", \"second\", \"second\", \"second\", \"second\", \"secret\", \"secret\", \"secret\", \"secret\", \"secret\", \"secret\", \"secret\", \"secretary\", \"secretary\", \"secretary\", \"secretary\", \"secure\", \"secure\", \"secure\", \"secure\", \"secure\", \"security\", \"security\", \"security\", \"security\", \"security\", \"security\", \"security\", \"sedan\", \"sedan\", \"sell\", \"sell\", \"sell\", \"sell\", \"sell\", \"sell\", \"sell\", \"sell\", \"senator\", \"senator\", \"send\", \"send\", \"send\", \"send\", \"send\", \"send\", \"send\", \"send\", \"sensor\", \"sensor\", \"sensor\", \"serbs\", \"serbs\", \"serdar\", \"serdar\", \"serdar\", \"series\", \"series\", \"series\", \"series\", \"series\", \"series\", \"series\", \"series\", \"serum\", \"serum\", \"server\", \"server\", \"server\", \"server\", \"server\", \"server\", \"server\", \"shaft\", \"shaft\", \"shaft\", \"shaft\", \"shaft\", \"shai\", \"shaig\", \"shameful\", \"sharks\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"shuttle\", \"shuttle\", \"side\", \"side\", \"side\", \"side\", \"side\", \"side\", \"side\", \"side\", \"simm\", \"simms\", \"skepticism\", \"skepticism\", \"skipjack\", \"software\", \"software\", \"software\", \"software\", \"software\", \"software\", \"software\", \"software\", \"soldier\", \"soldier\", \"soldier\", \"soldier\", \"soldier\", \"solntze.wpd.sgi.com\", \"solntze.wpd.sgi.com\", \"solntze.wpd.sgi.com\", \"sorenson\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"spacecraft\", \"spacecraft\", \"speed\", \"speed\", \"speed\", \"speed\", \"speed\", \"speed\", \"speed\", \"speed\", \"spirit\", \"spirit\", \"spirit\", \"spirit\", \"spirit\", \"spirit\", \"spirit\", \"stars\", \"steam\", \"steam\", \"sternlight\", \"steve\", \"steve\", \"steve\", \"steve\", \"steve\", \"steve\", \"steve\", \"steve\", \"steveh\", \"stimulus\", \"strnlght\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"survivors\", \"survivors\", \"svga\", \"syl.nj.nec.com\", \"talk\", \"talk\", \"talk\", \"talk\", \"talk\", \"talk\", \"talk\", \"talk\", \"taurus\", \"taurus\", \"tclock\", \"team\", \"team\", \"team\", \"team\", \"team\", \"team\", \"technology\", \"technology\", \"technology\", \"technology\", \"technology\", \"technology\", \"technology\", \"technology\", \"tempest\", \"tempest\", \"templeton\", \"territory\", \"territory\", \"territory\", \"territory\", \"territory\", \"territory\", \"terrorist\", \"terrorist\", \"terrorist\", \"theist\", \"theist\", \"thomasp\", \"thor.ins.cwru.edu\", \"thor.isc-br.com\", \"toal\", \"today\", \"today\", \"today\", \"today\", \"today\", \"today\", \"today\", \"today\", \"toronto\", \"toronto\", \"toronto\", \"toronto\", \"toronto\", \"treatment\", \"treatment\", \"treatment\", \"treatment\", \"treatment\", \"treatment\", \"treatment\", \"troop\", \"troop\", \"troop\", \"troop\", \"troop\", \"true\", \"true\", \"true\", \"true\", \"true\", \"true\", \"true\", \"true\", \"truth\", \"truth\", \"truth\", \"truth\", \"truth\", \"truth\", \"truth\", \"turkish\", \"turkish\", \"turkish\", \"turkish\", \"turks\", \"turks\", \"turks\", \"turn\", \"turn\", \"turn\", \"turn\", \"turn\", \"turn\", \"turn\", \"turn\", \"turpin\", \"unisql.uucp\", \"universe\", \"universe\", \"universe\", \"universe\", \"universe\", \"universe\", \"universe\", \"uokmax.ecn.uoknor.edu\", \"uokmax.ecn.uoknor.edu\", \"upgrade\", \"upgrade\", \"utkvm1.utk.edu\", \"utkvm1.utk.edu\", \"veal\", \"veal\", \"venus\", \"verse\", \"version\", \"version\", \"version\", \"version\", \"version\", \"version\", \"version\", \"version\", \"vesselin\", \"vesselin\", \"vice.ico.tek.com\", \"vice.ico.tek.com\", \"video\", \"video\", \"video\", \"video\", \"village\", \"village\", \"village\", \"village\", \"village\", \"violent\", \"violent\", \"violent\", \"violent\", \"visual\", \"visual\", \"vram\", \"waco\", \"waco\", \"waco\", \"waco\", \"wagon\", \"water\", \"water\", \"water\", \"water\", \"water\", \"water\", \"water\", \"water\", \"weapon\", \"weapon\", \"weapon\", \"weapon\", \"weapon\", \"weapon\", \"wharfie\", \"widget\", \"widget\", \"window\", \"window\", \"window\", \"window\", \"window\", \"window\", \"window\", \"windows\", \"windows\", \"windows\", \"wingate\", \"wings\", \"wings\", \"wings\", \"wire\", \"wire\", \"wire\", \"wire\", \"wire\", \"wiretap\", \"wiring\", \"withdrawal\", \"woman\", \"woman\", \"woman\", \"woman\", \"woman\", \"woman\", \"woman\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"wrong\", \"wrong\", \"wrong\", \"wrong\", \"wrong\", \"wrong\", \"wrong\", \"wrong\", \"x-soviet\", \"x11r5\", \"xlib\", \"xterm\", \"yeast\", \"yoyo.cc.monash.edu.au\", \"zoo.toronto.edu\", \"zoology\", \"zuma.uucp\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [6, 8, 4, 3, 2, 1, 7, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el275214097473083208394728996\", ldavis_el275214097473083208394728996_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el275214097473083208394728996\", ldavis_el275214097473083208394728996_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el275214097473083208394728996\", ldavis_el275214097473083208394728996_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "5     -0.180122  0.028800       1        1  22.812736\n",
       "7      0.097876  0.065061       2        1  16.297151\n",
       "3     -0.042212 -0.165432       3        1  13.698205\n",
       "2     -0.009565 -0.040330       4        1  11.975164\n",
       "1      0.071267  0.029143       5        1   9.843306\n",
       "0      0.175018  0.030246       6        1   9.379432\n",
       "6     -0.113074  0.140160       7        1   8.872125\n",
       "4      0.000813 -0.087649       8        1   7.121881, topic_info=            Term         Freq        Total Category  logprob  loglift\n",
       "1135        game  1770.000000  1770.000000  Default  30.0000  30.0000\n",
       "634         team  1588.000000  1588.000000  Default  29.0000  29.0000\n",
       "470        jesus  1254.000000  1254.000000  Default  28.0000  28.0000\n",
       "136         chip  1417.000000  1417.000000  Default  27.0000  27.0000\n",
       "285         file  2699.000000  2699.000000  Default  26.0000  26.0000\n",
       "...          ...          ...          ...      ...      ...      ...\n",
       "786   california   158.548885   628.976863   Topic8  -6.0299   1.2640\n",
       "249        power   164.865419  1583.867362   Topic8  -5.9908   0.3795\n",
       "211         cost   152.720376   922.239004   Topic8  -6.0673   0.8438\n",
       "478       little   151.298866  1504.092084   Topic8  -6.0767   0.3453\n",
       "15         model   145.154940   679.999205   Topic8  -6.1181   1.0977\n",
       "\n",
       "[618 rows x 6 columns], token_table=      Topic      Freq                   Term\n",
       "term                                        \n",
       "4623      5  0.955387             30602-7415\n",
       "4624      5  0.955387               542-0358\n",
       "4192      7  0.980785                 80-bit\n",
       "415       1  0.016336               absolute\n",
       "415       2  0.894398               absolute\n",
       "...     ...       ...                    ...\n",
       "3229      2  0.979849                  yeast\n",
       "2501      6  0.984636  yoyo.cc.monash.edu.au\n",
       "2923      3  0.991159        zoo.toronto.edu\n",
       "3115      3  0.983454                zoology\n",
       "1803      8  0.985749              zuma.uucp\n",
       "\n",
       "[2098 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[6, 8, 4, 3, 2, 1, 7, 5])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis = pyLDAvis.gensim.prepare(lda_model, M1, dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the results make more sense, and the coherence score has improved a little bit more. Now you should be able to use this code as an initial template for your topic models. In case that you face any problems, you can extend this template. As an example, you can change the number of topics and passes, limit the dictionary, extend the preprocessing module (e.g., removing the emails and web addresses, [stemming the text](https://blog.bitext.com/what-is-the-difference-between-stemming-and-lemmatization/), ...), use [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf), ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good Luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
